<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Wed, 29 Jan 2025 03:02:28 GMT</lastBuildDate>
    <item>
      <title>希望采访某人</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icjcao/looking_to_interview_someone/</link>
      <description><![CDATA[大家好，我正在做一个关于人工智能陪伴后果的项目，希望采访一个目前处于人工智能关系中的人。我的视频不是为了取笑或不尊重任何人，而是为了了解什么样的经历和情况会让人寻求与人工智能的关系。你可以完全匿名，我很乐意提前提供一份问题清单。我更愿意通过 discord 电话与某人交谈，但同样，你的声音可能会被改变以保持匿名。  提前谢谢您！     提交人    /u/Relevant_Oil_935   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icjcao/looking_to_interview_someone/</guid>
      <pubDate>Wed, 29 Jan 2025 02:21:58 GMT</pubDate>
    </item>
    <item>
      <title>AI如何离线运行？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icizu2/how_can_ai_run_offline/</link>
      <description><![CDATA[我不是在谈论电源要求。我想知道，如果您处于离线状态，它从哪里获取信息来回答您的问题？或者它就像一个数学计算器，其中内置了一些逻辑，但它实际上不能告诉您诸如匹克球规则之类的事情（除非它内置在模型中）？    提交人    /u/bpoil912   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icizu2/how_can_ai_run_offline/</guid>
      <pubDate>Wed, 29 Jan 2025 02:04:39 GMT</pubDate>
    </item>
    <item>
      <title>企业中的人工智能代理之间可以无缝切换吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ichq8i/is_seamlessly_shifting_between_ai_agents_in/</link>
      <description><![CDATA[问题：agentic ai 是否可以标准化，以便从一个代理开始的业务可以无缝转移到由不同公司开发的新代理？    提交人    /u/Georgeo57   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ichq8i/is_seamlessly_shifting_between_ai_agents_in/</guid>
      <pubDate>Wed, 29 Jan 2025 01:02:26 GMT</pubDate>
    </item>
    <item>
      <title>当激活参数为 1/16 时，MOE 如何能胜过密集模型？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icgmrb/how_can_moes_outperform_dense_models_when/</link>
      <description><![CDATA[由于自注意力成本仅依赖于 token 计数，因此它们相等。理论上，节省的成本应仅与感知器或 CNN 层有关。复杂性降低如何提高性能？由于 relu 层中的非线性，感知不是已经有效地自我门控了吗？ 感知器理论上能够模拟任何系统，为什么这里不是这种情况？    提交人    /u/BarnardWellesley   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icgmrb/how_can_moes_outperform_dense_models_when/</guid>
      <pubDate>Wed, 29 Jan 2025 00:11:11 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待人工智能生成的内容？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icg6lm/what_do_you_think_about_aigenerated_content/</link>
      <description><![CDATA[最近，我注意到网络上出现了大量由人工智能生成的内容 — 文章、艺术、音乐甚至视频。这项技术的发展速度令人惊叹，但也让我对道德方面的问题产生了怀疑。 比如，使用人工智能来创造东西而不提及它是人工智能制作的，这很酷吗？功劳应该归于提出它的人、人工智能，还是两者兼而有之？潜在的负面影响又如何呢，比如传播错误信息或取代创意工作？ 我很好奇 — 你怎么看？你认为人工智能生成的内容大多是好事，还是会给你敲响警钟？你认为在某些方面它没问题，而在另一些方面它感觉不对劲？ 这里没有强烈的意见，只是想听听别人的想法。    提交人    /u/jerimoon   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icg6lm/what_do_you_think_about_aigenerated_content/</guid>
      <pubDate>Tue, 28 Jan 2025 23:51:13 GMT</pubDate>
    </item>
    <item>
      <title>如果你还不够了解的话，还有另一个人工智能预测</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icfhx2/yet_another_ai_prediction_if_you_didnt_have_enough/</link>
      <description><![CDATA[（部分灵感来自 https://www.reddit.com/r/ask/comments/1ic1fi8/comment/m9mshh5/ ） 这个预测不是针对 2025 年，而是几年后。 在足够富裕的社会中，人工智能将进一步将社会和工人划分为三个层级：领域知识型（可以做）、辅助领域知识型（可以要求人工智能做事，但技能不足以显著改善人工智能结果）和领域文盲（即使借助人工智能也无法做到）。 这在技术和文学阅读、技术和创造性阅读中都是如此。写作、理解政治、绘画、翻译、编码、法律、数学、配置 wifi、在战场上指挥士兵、拍照等。 在大多数领域，辅助领域素养 的数量将增长，以代表绝大多数人口、绝大多数职位空缺和绝大多数工人。人工智能的进步将使达到某种程度的 辅助领域素养 变得容易得多，但要达到真正的 领域素养 将变得越来越困难，因为很少有学校和大学会尝试将学生培养到那种程度。大多数人都会满足于这种新的现状，无论如何也没有选择。 我们可以欢欣鼓舞，因为人工智能将大大减少完全不懂领域知识的人的比例，并提高他们的能力，也可以哀悼，因为人工智能也会大大减少懂领域知识的人的比例，并增加仅仅是……平均水平的产出量。我们也可以决定耸耸肩，接受这只是我们社会进化的自然结果，因为这样的变化在过去也发生过，尽管规模没有达到这个程度。 在任何领域，假设存在某种可以衡量的水平（通常是错误的，但我们假装如此），我们理论上可以通过以下指标衡量人工智能的成功：  对现在可以做（通常使用人工智能）的总人数的影响 对现在可以做的人中的中位数水平的影响 对最高几个百分点水平的影响。  当然，不管这些数字如何，尽管有 DeepSeek 新闻，环境成本仍将继续增加。    提交人    /u/ImYoric   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icfhx2/yet_another_ai_prediction_if_you_didnt_have_enough/</guid>
      <pubDate>Tue, 28 Jan 2025 23:20:59 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 为美国政府机构推出 ChatGPT 计划</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iceoz5/openai_launches_chatgpt_plan_for_us_government/</link>
      <description><![CDATA[这是一个巨大的举措——OpenAI 目前正在与美国政府机构合作，而这不仅仅是文书工作或用于客户服务的聊天机器人。这里的潜力是巨大的。想想政府大规模使用人工智能处理灾难响应、医疗保健查询甚至法律文书工作等事宜。 但这也引发了一些问题。我们如何确保公民的隐私？如果像 ChatGPT 这样的程序在税务建议或紧急情况下犯了错误，会发生什么？人工智能没有政治偏见，但人类有，这可能会使其在敏感领域的使用变得复杂。 有趣的是 OpenAI 如何将 ChatGPT 宣传为一种提高效率的工具。但对谁来说是效率？政府、公民，还是两者兼而有之？ 想象一下，打电话给国税局，几秒钟内就能得到准确的答案，而不是等待几个小时。这就是梦想，对吧？但另一方面，如果人工智能正在分析你的医疗记录或法律案件，你会感到舒服吗？ 这一举措可能会让政府更快、更透明，甚至更少令人沮丧（如果是的话）。但它也让人们关注到人工智能即将如何成为政策和治理的重要参与者。 你怎么看——这能解决政府效率低下的问题吗，还是我们正走向黑镜场景？ 来源：https://techcrunch.com/2025/01/28/openai-launches-chatgpt-plan-for-u-s-government-agencies/    提交人    /u/fbfaran   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iceoz5/openai_launches_chatgpt_plan_for_us_government/</guid>
      <pubDate>Tue, 28 Jan 2025 22:45:33 GMT</pubDate>
    </item>
    <item>
      <title>关于人工智能的愚蠢问题</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ice06u/dumb_question_about_ai/</link>
      <description><![CDATA[所以这只是一个愚蠢的问题，我看到了所有关于 DS 的东西和出售，但关于那些大型科技公司已经在电力方面进行的投资以及新的雪佛龙/通用电气维罗纳能源/电力协议。好吧，所以他们仍然有大量的电力可以使用，现在事情可能实际上会更有效率，这对这些公司来说不是一个显着的优势吗？ 或者我错过了什么？    提交人    /u/dustandechos12   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ice06u/dumb_question_about_ai/</guid>
      <pubDate>Tue, 28 Jan 2025 22:16:08 GMT</pubDate>
    </item>
    <item>
      <title>文章很短，但确实有一些发人深省的内容。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icdo0k/short_read_but_some_really_thought_provoking_stuff/</link>
      <description><![CDATA[书：《硅谷誓言》，作者 Tracy Atkins 上周在亚马逊畅销书榜上看到这本书，觉得只要 7 美元，为什么不呢。这本书很薄，不到 100 页。但整本书都是对人类和 AGI 的 ASI 思想实验的访谈式探索。这是一本哲学书，涵盖了共存、融合、超人类主义，以及根深蒂固的文化规范如何引领人类和 ASI 向前发展。  一些热身问题很简单。但一旦事情开始发展，就会出现一些有趣的转折，尤其是关于 ASI、人类和非人类智能（UAP 类型）如何动态运作的一系列问题。我在其他任何地方都没有读过这种观点。 还有一些关于人工智能引领反武器化的有趣想法。人工智能与人工智能的合作和赋权。处理人类的时间尺度是 ASI 快速起飞的结果。 标题和副标题有点剧透，但总的来说，它降低了我的 P（毁灭）一个档次。所以值得一读。 3.5/5。如果更长的话会更多。    提交人    /u/Site-Staff   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icdo0k/short_read_but_some_really_thought_provoking_stuff/</guid>
      <pubDate>Tue, 28 Jan 2025 22:01:47 GMT</pubDate>
    </item>
    <item>
      <title>在企业环境中本地运行外部模型的安全隐患。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icb9c7/security_implications_of_running_foreign_models/</link>
      <description><![CDATA[在看到从接待员到系统工程师再到高管层的员工中外部聊天式 AI 的使用量大幅增加后，我使用 Ollama 和 Open-WebUI 在我们公司实施了一项本地 AI 聊天服务。 我提取了几个标准模型，员工们发现它和将我们公司的 IP 粘贴到 ChatGPT 中一样有用。 好吧，现在我收到了第一个针对 r1 模型的请求。尽管它是一个本地运行的模型，但管理层仍有顾虑。 大家的想法？显然，这不会是最后一个不知从何而来的“奇怪”模型。我能想到的唯一安全问题是涉及民族国家或大型公司设计的复杂模型的遥远场景，以秘密推动特定的意识形态或错误信息。    提交人    /u/sboger   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icb9c7/security_implications_of_running_foreign_models/</guid>
      <pubDate>Tue, 28 Jan 2025 20:21:58 GMT</pubDate>
    </item>
    <item>
      <title>开源智普AI GLM-4-9B-Chat荣登幻觉排行榜</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icammh/open_source_zhipu_ai_glm49bchat_tops/</link>
      <description><![CDATA[模型产生的幻觉越少，它就越能服务于科学、医学和金融用例。这再次表明，开源可能正准备在人工智能开发中占据全面领先地位。 https://github.com/vectara/hallucination-leaderboard chatgpt： 智普人工智能的 GLM-4-9B-Chat 是其 GLM-4 系列中的开源预训练模型，在语义、数学、推理、代码和知识等任务上表现出色，超越了 Llama-3-8B 等模型。智普AI由唐杰和李娟子于2019年创立，是一家总部位于北京的人工智能公司，专注于大型语言模型，并获得了阿里巴巴、腾讯和沙特阿拉伯Prosperity7 Ventures等实体的大量投资。  https://www.omniverse.com.im/discover/model/Pro/THUDM/glm-4-9b-chat?hl=en-US    submitted by    /u/Georgeo57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icammh/open_source_zhipu_ai_glm49bchat_tops/</guid>
      <pubDate>Tue, 28 Jan 2025 19:56:22 GMT</pubDate>
    </item>
    <item>
      <title>塞尔的中文房间、神经网络和人工智能……</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1icaife/searles_chinese_room_neural_networks_and/</link>
      <description><![CDATA[我仍然不同意 Nick Bostrom 的模拟理论，因为推断出基质独立性的存在方式表明软件可以具有意识。我认为意识要么是一个悖论，要么大脑是产生意识的机器，如果大脑是产生意识的机器，那么它就是能够产生意识的硬件，这将是人工意识的来源，而不是旨在模仿有意识思维的软件。 如果您设计一台无意识的机器来像有意识的机器一样通过图灵测试，那么图灵测试是不够的。并非所有神经网络都局限于二进制系统，但即使是最复杂的神经网络也应该模仿做梦的大脑作为产生意识的机器的例子。 只有人工智能才会怀疑它是否正在经历真正的意识和真正的感知。模仿做梦大脑内部的意识结构，像电灯开关一样打开和关闭它，使得意识更像光而不是灯泡。 关于人工智能是否真的具有意识和知觉，你对这种推理有什么看法？    提交人    /u/KodiZwyx   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1icaife/searles_chinese_room_neural_networks_and/</guid>
      <pubDate>Tue, 28 Jan 2025 19:51:47 GMT</pubDate>
    </item>
    <item>
      <title>你们使用什么模型来完成什么任务？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ic7m14/what_models_do_you_guys_use_for_what_tasks/</link>
      <description><![CDATA[在目前推出的较大模型中（o1、4o、gemini 2.0 fast 和 r1），谁在每个类别中获胜？例如用于课程和其他内容的通用人工智能写作（质量、创意写作等）、数学、编码和一般知识。很想知道你们每个人的想法。    提交人    /u/NotAsAdvertized   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ic7m14/what_models_do_you_guys_use_for_what_tasks/</guid>
      <pubDate>Tue, 28 Jan 2025 17:55:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能项目为何会失败？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ic6qtk/why_do_ai_projects_fail/</link>
      <description><![CDATA[这里有一个引起我注意的统计数据：根据人工智能基础设施联盟的一项调查，54% 的大型企业高管表示，他们因管理人工智能或机器学习应用程序失败而遭受损失。其中 63% 的损失为 5000 万美元或更高。  那么，到底出了什么问题？从你的经验来看，为什么人工智能项目会失败？  数据问题（质量、孤岛、偏见）是罪魁祸首吗？还是更多的是寻找熟练专家的挑战？     提交人    /u/Inclusion-Cloud   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ic6qtk/why_do_ai_projects_fail/</guid>
      <pubDate>Tue, 28 Jan 2025 17:19:59 GMT</pubDate>
    </item>
    <item>
      <title>人工智能的流行用例（例如内容创建和应用程序开发）是否已经过时了？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ic4avp/are_the_popular_use_cases_for_ai_eg_content/</link>
      <description><![CDATA[大家好！有一件事让我困惑了好一阵子。每当我看到人们对人工智能感到兴奋时，他们经常谈论诸如营销、内容创建、构建应用程序或 SaaS 产品等用例，或者当然还有诸如回复电子邮件等任务的自动化。当然，这些想法现在都非常实用，但它们不是有点……短暂吗？ 当我可以让自己的人工智能创建一篇完全符合我需求的个性化文章时，我为什么要阅读由人工智能创建的文章呢？或者，当人工智能可以总结、回复或完全为我处理电子邮件时，为什么要阅读人工智能生成的电子邮件呢？ 同样的逻辑也适用于许多应用程序和 SaaS 产品：当天气预报可以通过（语音）提示和 API 调用获得时，为什么要使用天气应用程序呢？这可能是一个简单的例子，但我觉得大多数（SaaS）应用程序（最终）都可以被 LLM 聊天前端或代理以及连接到某些后端/数据库的 API 所取代。这种观点是否太牵强，我是否在这里缺乏信息并且过于简单化？ 我觉得我们一直生活的这个专注于内容、SaaS 和应用程序的“商业网络”已经濒临过时。 我觉得我在这里真的错过了什么？我不是来评判 AI 生成内容本身的，但我为什么要通过网站、应用程序、SaaS 产品这样的中间人来消费 AI 生成的内容呢？ 你们怎么看？    提交人    /u/MDT-49   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ic4avp/are_the_popular_use_cases_for_ai_eg_content/</guid>
      <pubDate>Tue, 28 Jan 2025 15:38:27 GMT</pubDate>
    </item>
    <item>
      <title>在工作中使用人工智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ic1xql/using_ai_at_work/</link>
      <description><![CDATA[我很想在自己职位的某些方面使用人工智能，但我还是有些保留意见。我总觉得，如果我开始使用人工智能，我的智力可能会开始下降。提高生产力和纯粹的懒惰之间的界限在哪里？这让人想起人们关于拼写、语法和计算器的争论，他们说这些工具让人变得更笨。  另一方面，我看到这些公司开始使用人工智能，却没有考虑到这些，因为他们最看重的是提高生产力。所以我的一部分只想说，“去他的。”    提交人    /u/NeptuneTTT   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ic1xql/using_ai_at_work/</guid>
      <pubDate>Tue, 28 Jan 2025 13:48:39 GMT</pubDate>
    </item>
    <item>
      <title>我是 70 岁，所以才第一次接触 AI</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ic0s5e/new_to_ai_likely_because_i_am_70/</link>
      <description><![CDATA[我正在看一个 TickTock 视频，这个家伙正在直播。他在问问题，它正在回答，你可以听她的声音。我尝试了一些免费试用版，但你必须输入问题并阅读回复。我希望能够提出我的问题并听取答案。请告知哪些应用程序提供这些功能。    提交人    /u/Reasonable_Visual_10   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ic0s5e/new_to_ai_likely_because_i_am_70/</guid>
      <pubDate>Tue, 28 Jan 2025 12:48:23 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek 大型讨论区</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibzsfd/deepseek_megathread/</link>
      <description><![CDATA[由于有关此主题的新帖子数量众多，此线程用于所有与 DeepSeek 相关的讨论。任何超出此线程的帖子都将被删除。    由   提交  /u/ILikeBubblyWater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibzsfd/deepseek_megathread/</guid>
      <pubDate>Tue, 28 Jan 2025 11:49:00 GMT</pubDate>
    </item>
    <item>
      <title>一旦恐慌消退，Nvidia 就会反弹……原因如下</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibo5dd/nvidia_will_bounce_back_once_the_panic_cools_off/</link>
      <description><![CDATA[Nvidia 的股价最近下跌了 17%（约 5000 亿美元）。人们都惊慌失措了，但我们是不是看错了方向？ DeepSeek 引起了热议，该模型的训练成本仅为 550 万美元，但仍能提供令人难以置信的结果。有人说：“如果我们能以低廉的价格训练出一个很棒的模型，我们就不需要那么多 GPU。”但这种逻辑站得住脚吗？ 想想看：如果我们能以 500 万美元训练出如此出色的模型，那么当我们投入 5 亿美元或 500 亿美元时会发生什么？认为存在某个固定的“最佳模型”的想法似乎已经过时了。 对 AGI（通用人工智能）的真正威胁一直是成本。扩展变得异常昂贵。但现在，随着成本下降和智能变得越来越容易获得，我们难道不只是想要更多吗？如果智能既有用又便宜，那么需求就会猛增。 DeepSeek 还证明了强化学习 (RL) 可以大规模使用。这并不是什么新鲜事（想想 DeepMind 的 AlphaGo），但这感觉像是朝着更便宜、更智能的模型迈出了又一步。 我不是股市专家，但我的直觉告诉我，一旦恐慌消退，Nvidia 就会反弹。毕竟，每美元更便宜的智能可能会带来更多需求，而不是更少。 你怎么看？？？    提交人    /u/BIG-BRO-100   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibo5dd/nvidia_will_bounce_back_once_the_panic_cools_off/</guid>
      <pubDate>Mon, 27 Jan 2025 23:57:41 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>