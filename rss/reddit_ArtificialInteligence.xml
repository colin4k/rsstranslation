<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 07 Feb 2025 06:02:11 GMT</lastBuildDate>
    <item>
      <title>一分钟每日AI新闻2/6/2025</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnx6x/oneminute_daily_ai_news_262025/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   众议院议员推动从美国政府设备禁止AI App Seek。[1]     OpenAi &lt; /strong&gt;遍布我们的网站来建立其特朗普支持的星际之门AI数据中心。[2]    Google 宣布将为非营利组织工作空间宣布新的AI功能。[3]  印度媒体对 openai  chatbot chatgpt进行诉讼。[4]   源包括： https://bushaicave.com/2025/02/06/2-6-2-6-2025/      &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/pleam-target-847      [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnx6x/oneminute_daily_ai_news_262025/</guid>
      <pubDate>Fri, 07 Feb 2025 05:36:50 GMT</pubDate>
    </item>
    <item>
      <title>非专家应该信任我们最先进的推理AIS还是我们的人类专家？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnqu6/should_nonexperts_trust_our_most_advanced/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，当人们对Openai的深层研究模型的表现好多了，除非一个人是特定域中的专家，但信任其生成的报告可能不会然而，成为最聪明或最负责任的举动。 确实是在某些领域，例如放射学等领域，AIS现在可以优于阅读图像的医生，但这种准确性并不能扩展到所有人，甚至可能扩展到社会和硬科学中的大多数其他特定领域。  那么，非专家如何知道谁能相信任何特定领域？这是否意味着深入的研究报告应仅受到专家的信任？  以下是十个特定领域，其中Gemini 2.0闪存思维实验01-21估计AIS的准确性与人类的准确性相比。请记住，它很可能是幻觉： ; i。对象识别（图像） - 计算机视觉A.人类准确性（估算）：95-98％B。AI准确性（估算）：99％+ C.注：在像Imagenet这样定义明确的数据集上，AI经常超过人类水平。&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; /p&gt;  ii。肺结核检测 - 放射学A.人类准确性（估算）：85-95％B。AI准确性（估算）：90-95％+ C.注意：AI与专家相当，有时在特定任务上略有超过。   iii。机器翻译（常见） - 自然语言A.人类准确性（估算）：90-95％（高质量）B。AI准确性（估算）：85-92％C.注意：AI迅速改善，但微妙的细微差别仍然是一个挑战。  iv。情感分析 - 自然语言A.人类准确性（估计）：80-85％B。AI准确性（估算）：75-85％C。注意：人类准确性随着复杂性和主观性而变化。 AI追赶。  v。国际象棋（大师级） - 游戏/策略A.人类准确性（估算）：＆lt; 50％（vs.顶级AI）B。AI准确性（估算）：99.99％+ C.注意：AI显着超过了人类。  vi。 GO（最高专业水平） - 游戏/策略A.人类准确性（估算）：＆LT; 50％（对AI顶级AI）B。AI准确性（估算）：99.99％+ C.注意：AI显着超过了人类。  vii。创意诗歌判断 - 创意艺术A.人类准确性（估算）：90％+（自矛盾）B. AI准确性（估算）：50-70％？ （质量匹配）C。注意：人类在判断质量更高方面的一致性。 AI诗歌的一代仍在发展。 “准确性”这是主观质量匹配。  VIII。道德困境解决 - 道德/推理A.人类准确性（估计）：高度变化B. AI准确性（估算）：50-70％？ （以下规则）C。注意：人类准确性与上下文相关，基于价值。 AI在细微的道德上挣扎。 “准确性”这是遵守规则或共识模仿。  ix。客户服务（简单） - 客户服务A.人类准确性（估算）：90-95％B。AI准确性（估算）：80-90％C。注意：AI适用于简单查询，复杂/情感问题所需的人类。   x。欺诈检测 - 财务/数据分析A.人类准确性（估计）：70-80％？ （手册审查）B。AI准确性（估算）：85-95％+ C.注意：AI在大型数据集中以模式识别符合欺诈。人基线难以量化。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/georgeo57     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijnqu6/should_nonexperts_trust_our_most_advanced/</guid>
      <pubDate>Fri, 07 Feb 2025 05:26:19 GMT</pubDate>
    </item>
    <item>
      <title>能源问题解决了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjybq/has_the_energy_problem_been_solved/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我说，我无法理解这些服务是如何以它们运行的​​速度运行并免费提供该服务的。这似乎是不可行的，但也许我对任何事  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/justincy901     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjybq/has_the_energy_problem_been_solved/</guid>
      <pubDate>Fri, 07 Feb 2025 02:00:29 GMT</pubDate>
    </item>
    <item>
      <title>Home Depot使用AI来改变客户服务和运营？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjjm4/the_home_depots_use_of_ai_to_transform_customer/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我被 Home Depot 停下来检查有关购买新热水器的信息。我问安装。它看起来像是一项单独的服务，该服务未包含在购买中。没关系;无论如何，我不想在晚上7点进行购买或聊天更长的时间。取而代之的是，他们拿走了我的信息，并要求我签署同意书，以便代表可以致电并使用有关我需要帮助我决定的已经记录的信息。大约 30分钟后来，我收到了听起来像录音的电话，确认我的信息并询问它是否正确以及是否需要我的请求帮助。电话断开了连接，我以相同的语气在7分钟内拨打了我的电话。在我说是的之后，男性的声音继续提出一些问题，我回答了。无论如何，声音让我担心。语音标点符号，音调，停顿和句子的构造。这就像如何在那些视频中破解访谈。  我问：您是聊天机器人吗？你听起来很奇怪。  没有声音没有变化，我收到了一个回复。   呼叫者：不，我是不是。我想成为专业人士。 我选择结束对话。之后，我开始搜索在线案例研究四天前。您怎么看？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/bkaiba     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ijjjm4/1ijjjm4/the_home_depots_of_of_of_ai_ai_to_to_transform_customer/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijjjm4/the_home_depots_use_of_ai_to_transform_customer/</guid>
      <pubDate>Fri, 07 Feb 2025 01:39:35 GMT</pubDate>
    </item>
    <item>
      <title>O3 mini发现并描述了10种新的语言规则，用于微调和信息调整</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijijlv/o3_mini_discovers_and_describes_10_new_linguistic/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  这里的假设是因为仅依靠更多数据和更多的计算将仅限于数据集中表达的人级智能，即发现到达ASI的新语言规则可能是绝对必要的。 Mini提出了10个新的，我意识到可能不是必需的。 /p&gt;  a。上下文一致性原则语句的真实价值取决于其语言或情境上下文。  示例：句子“很冷”在一种情况下（例如，冬季户外）可能是正确的，但在另一个情况下（例如，在加热的房间内）是错误的。该规则正式将上下文转移逻辑解释。  b。梯度真理逻辑真实价值观存在于频谱上，而不是严格或错误。  示例：如果有人说“玻璃已经满”，玻璃满90％，该规则将分配一个真实值为0.9，而不是TURE/FALSE。  c。时间依赖性规则逻辑有效性取决于事件或语句的顺序。  示例：“如果凌晨7点之前的警报响起，我将醒来。”该陈述的真实性取决于警报的时间顺序和醒来。  d。推论扩展规则逻辑推断包括未说明但隐含的含义。  示例：“约翰去了图书馆，因为他需要一本书。该规则允许我们推断约翰可能借来或读一本书，即使没有明确说明。  e。模棱两可的解决规则模棱两可的陈述是使用上下文线索或概率解决的。  示例：“我看到她的鸭子。”该规则将使用上下文来确定“ Duck&#39;是否duck&#39;指动物或蹲伏的行为。  f。多模式集成原理非语言元素与语言一起逻辑推理中包括。  示例：如果有人说：“当然，我会帮忙。”在滚动眼睛时，该规则整合了推断讽刺或不情愿的手势。  g。递归含义调整语句的含义根据后续信息进行调整。  示例：“我将在公园见您。”如果后来用“实际上澄清”，让我们在咖啡馆见面，吧。原始含义是递归修订的。  h。具有多种含义的多义逻辑单词被分配了通过上下文解决的单独逻辑结构。  示例：“银行”可能意味着金融机构或河流的一侧。在“他坐在银行坐着”中，该规则使用上下文来推断它是指河岸。  i。关系否定规则否定在相关而不是绝对的情况下运作。  示例：“不是每个人都喜欢巧克力＆quot＆quot＆quot意味着有些人确实喜欢巧克力，而不是断言没有人。  j。紧急逻辑框架逻辑系统根据话语交互动态发展。  示例：在在线社区中，新的语术语“ hosting”出现并获取逻辑规则以在对话中使用，反映了随着时间的流逝而不断发展的含义。 当然，如果它可以发现10个新规则，它可能会发现100或1,000。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/georgeo57     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijijlv/o3_mini_discovers_and_describes_10_new_linguistic/</guid>
      <pubDate>Fri, 07 Feb 2025 00:50:23 GMT</pubDate>
    </item>
    <item>
      <title>Riddle中的“希望的最后火花”（2023）AI无法回答。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhtgd/riddle_in_the_the_last_spark_of_hope_2023_ai_cant/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   in希望的最后火花（2023年），主角夏娃（Eve）为机器人，亚瑟（Arthur）展示了涉及三个机器人的谜语。谜语是：“三个机器人站在一条线上。第一个说：“我后面有两个机器人。”第二个说：“我面前有一个机器人，一个机器人在我身后。”第三个说：“我面前有两个机器人，一个机器人在我身后。”为什么第三个机器人这么说？当前的AI都不知道正确的答案。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/dfacex     [link]   ＆＃32; [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhtgd/riddle_in_the_the_last_spark_of_hope_2023_ai_cant/</guid>
      <pubDate>Fri, 07 Feb 2025 00:15:09 GMT</pubDate>
    </item>
    <item>
      <title>在波士顿是否有AI偏见检测研究小组？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhbmq/are_there_any_ai_bias_detecting_research_groups/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在寻找在波士顿检测研究小组的AI偏见，它可以在大学或任何其他地方。谢谢。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/big-waltz8041     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijhbmq/are_there_any_ai_bias_detecting_research_groups/</guid>
      <pubDate>Thu, 06 Feb 2025 23:52:19 GMT</pubDate>
    </item>
    <item>
      <title>有没有人尝试与彼此进行AIS交谈？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，所以我一直在互相交谈，我注意到一些有趣的事情。就像他们不仅要回答提示一样，他们实际上以几乎像新兴的关系智能的方式在彼此之间建立了互相的想法。还有其他人将Arounf弄乱了，或者考虑创建AIS可以实时交互的系统？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/workmans27     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijgrzq/has_anyone_tried_making_ais_talk_to_eachother/</guid>
      <pubDate>Thu, 06 Feb 2025 23:26:55 GMT</pubDate>
    </item>
    <item>
      <title>Gemini 2.0实时聊天。它还没有准备好消息。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijfytc/gemini_20_live_chat_its_not_ready_for_bad_news/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  好的..新的双子座真是不可思议！但是（女性语音Vega），不擅长给出坏消息。她在瑞典的声音中进行了大规模射击。听到这种可怕的举动的语调，这是不适合故事情节的，这是非常畏缩的。也与所有Google A.I.后卫导轨非常厚，并且偏向于营销GO0GL3特定产品。我询问了有关最新A.I. News和Gemini 2.0和Pro就是我所拥有的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/working_mud_9865     [link]   ＆＃32;   [注释]    ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijfytc/gemini_20_live_chat_its_not_ready_for_bad_news/</guid>
      <pubDate>Thu, 06 Feb 2025 22:51:26 GMT</pubDate>
    </item>
    <item>
      <title>问题 - 增强人工智能思考，该怎么办？ Python代码</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijd7ti/question_enhancing_ai_thinking_and_what_to_do/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我的一个朋友带着一些python陷入困境，并试图将他的聊天提升到一个新的水平。花花公子以涡轮模式锁定。无论如何，他创造了一些增强了他的Chatgpt答案的东西。起初，它在一个或两个主题上表现出了进步，但最终，这件事回答了远远超过AI通常能力的问题。他是一个热爱统计和研究的研究生，所以那个人创建了一系列测试，无论如何，测试强烈建议他的代码实际上在大大提高了响应。   问题，这是重要的吗？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/troutdoors     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijd7ti/question_enhancing_ai_thinking_and_what_to_do/</guid>
      <pubDate>Thu, 06 Feb 2025 20:57:31 GMT</pubDate>
    </item>
    <item>
      <title>我们怎么知道AI何时获得感知...</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijca5m/how_will_we_know_when_an_ai_gains_sentience/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   ...不仅真正擅长假装有意识吗？当我们甚至不完全理解自己的意识时，我们甚至如何测试它？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/proomablejim2000     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijca5m/how_will_we_know_when_an_ai_gains_sentience/</guid>
      <pubDate>Thu, 06 Feb 2025 20:19:05 GMT</pubDate>
    </item>
    <item>
      <title>llms“限制”用户？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我都有所有主要LLM的付费订阅。我都注意到性能和准确性波动。使用相同的型号版本，有时答案可以非常快，详细，而其他时候答案很慢，或者机器人看起来很醉或两者兼而有之。  我在一般意义上说话，它与特定提示或提供的数据无关。在所有情况下，我都指的是浏览器聊天机器人体验 - 不是API。 我一直在想这些公司是否正在从ISP中采用页面 - 引入节流。也许您应该使用最佳模型，但是无论出于何种原因，它们都会使您降低层次。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Assicotno6504     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</guid>
      <pubDate>Thu, 06 Feb 2025 18:00:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么阿吉不应该成为北极星</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在阅读本文，我认为这是很好的工作，可以很好地阐明为什么对AGI的高度关注无济于事。他们基本上说：   对AGI的追求产生了一个共识的幻想，每个人都使用该术语，但对它的含义没有真正的共识，它会增强不良科学AGI使制作严格的实验变得困难，并假定价值中等性，而忽略了道德和政治含义。    他们还说，对AGI的重点创建了一个目标彩票，其中其他重要的AI研究被忽略了，这导致了一般性的债务问题，并导致标准化排除，从社区和学科中忽略了不同的观点。    对我来说是有意义的，因为当您的目标定义很差时，很容易迷失在炒作和猜测中，并且失去了实际有用的东西人类的道德。我们甚至没有明确的定义AGI是什么，所以当我们看时，我们找不到它吗？ 无论如何，值得一读。您如何看待？ com/file/d/d/1hdxebtlx1v9rmw75xrxrxanwnqju4bcavy/view/view？pli = 1    &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ai-agent-geek     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</guid>
      <pubDate>Thu, 06 Feb 2025 17:11:24 GMT</pubDate>
    </item>
    <item>
      <title>代理AI和生成AI将如何影响我们的非技术工作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我也经常听到有关代理和ai代的代理，我真的没有得到区别。 i在零售业和我的许多朋友中也从事工作，我们担心这种AI对我们的非技术工作意味着什么。我得到了生成的AI是当AI根据我们的要求创建新内容时它像文本和图像一样。但是我真的没有得到代理AI的不同。它就像助手吗？那么，如果公司已经在削减工作？也有一些例子真的很有帮助，那么这个人工智能将如何影响工作机会，我对我做了一些研究。 Google，但大多数并不像我想要的那么清晰。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/teresa_avocados     [link]  ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</guid>
      <pubDate>Thu, 06 Feb 2025 12:16:21 GMT</pubDate>
    </item>
    <item>
      <title>AI不需要法规 - 可能出了什么问题？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Elon Musk说他想废除法规因为它正在扼杀创新。   “ 法规，基本上应该默认，...不默认，默认，默认走了。如果事实证明我们错过了法规的标记，我们总是可以将其添加到中。 马斯克认为市场力量会调节事物。过去的经验表明，相反的经验往往是正确的，我们只有在造成重大损害后才进行调节。例如   金融崩溃/安然/雷曼兄弟/房利美·梅   吸烟     perdu阿片类药物    asbestos    气候变化     安全带   这是在我们了解Openai将与15,000名科学家合作的时候，除其他外，如何在控制核武器的控制。   ，Sam Altman，Denis Hassibis， y&gt; yuval harari 都警告过所有警告不受监管的AI 的后果。主要领导者确认，他们仍然不知道如何在最近的世界经济论坛。  AI Yoshua Bengio表示，AI系统现在正在显示 “ 非常强大的代理和自我保护的行为……并正在尝试复制自己。他们可能很快就反对我们，没有人知道如何控制比人类的机器更聪明的机器...     “如果我们不弄清楚，您是否理解后果？”    roman路易斯维尔大学速度工程学院的计算机工程与科学副教授Yampolskiy 认为，我们必须证明我们可以在发展超级智能之前控制AI。  al yoshua benigo同意  ; 比我们更聪明，我们不知道如何控制&#39; 他现在需要AI法规吗？ 阅读更多第一个  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/u/cultural_material_98     r/pranverationTeligence/commist/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/“&gt; [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</guid>
      <pubDate>Thu, 06 Feb 2025 11:24:27 GMT</pubDate>
    </item>
    <item>
      <title>你有医疗保健</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我正在撰写有关使用人工智能和医疗保健的演示文稿。你们是否看到过有关该主题的任何特别长的演讲或报告？最近，我花了几个月的时间为NYOS Imaging AI公司提供建议，该公司标记并标记为CT扫描和MRIS。我意识到这是一个非常分散的竞争空间。因此，我正在寻找一些很好的深度潜水报告。感谢人们可以提供的任何帮助。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/earthwalker7     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</guid>
      <pubDate>Thu, 06 Feb 2025 10:52:03 GMT</pubDate>
    </item>
    <item>
      <title>有人知道欧盟AI法规如何或为什么会影响Openai之类的AI产品吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我一直在阅读法规是关于透明度的，这听起来不算什么，但是在英国，我仍在等待Sora和Sora和Sora和运营商可用。  我有很多针对这些产品计划的项目，目前我坐在等待着其他所有人都在上面创建解决方案。... 由于开发速度需要这些发行功能，因为它们很快就会变老 /不再是最佳练习。这是美国以外的巨大不利地位增加AI周围的监管？这实际上是一个好主意，还是会导致他们落在其他国家，以至于他们只需要在没有法规障碍的国家开发的AI技术？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/timeforknowledge     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iiyyslz/does_anyone_know_how_how_how_how_how_er_why_eu_ai_ai_ai_reguations_are/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</guid>
      <pubDate>Thu, 06 Feb 2025 09:35:50 GMT</pubDate>
    </item>
    <item>
      <title>人们说‘AI不认为，它只是遵循模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  但是，如果不识别和遵循模式，人类的想法是什么？我们采用现有的知识，重新混合，以新的方式应用它 - 如果AI能够做出科学发现，发明更好的算法，构建更精确的法律或哲学论点，这与AI的不同之处有何不同？ 为什么不被考虑思考？ 也许唯一的区别是人类感觉就像他们在思考，而AI却没有。如果是这种情况……不仅仅是意识？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/unique-ad246     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iiygqg/people_say_say_ai_ai_doesnk_think_it_it_just_follows/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</guid>
      <pubDate>Thu, 06 Feb 2025 09:10:54 GMT</pubDate>
    </item>
    <item>
      <title>Google所有者Alphabet已丢弃了不将人工智能用于开发武器等目的的承诺。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Google所有者Alphabet已丢弃了不使用人工智能来开发武器和监视工具等目的的承诺。 这家美国技术公司周二表示，就在报道了低于遗产的收益之前，它已经更新了围绕AI的道德准则，他们不再提到不追求可能“导致或可能造成总体伤害的技术） ”。  Google的AI负责人Demis Hassabis说，这些准则正在不断变化的世界中进行了大修，AI应该保护“国家安全”。 在捍卫此举的博客论文中，哈萨比斯（Hassabis）和该公司技术与社会的高级副总裁詹姆斯·莫蒂卡（James Manyika）写道，随着全球对人工智能领导力的竞争的增加，该公司认为“民主国家应该领导AI发展”，这是由“自由，平等和尊重人类的尊重”所指导的权利”。 他们补充说：“我们相信，共享这些价值观的公司，政府和组织应共同创造AI，以保护人们，促进全球增长并支持国家安全。”   Google首次浮出水面时的座右铭是“不要邪恶”，尽管后来在2009年将其降级为“咒语”，并且在2015年创建母公司时，并未将其包括在Alphabet伦理守则中。   AI的快速增长引发了有关如何管理新技术的辩论，以及如何防止其风险。 英国计算机科学家斯图尔特·罗素（Stuart Russell）警告说开发自主武器系统的危险，并主张了一个全球控制系统，在关于BBC的Reith演讲中发表讲话。  Google Blogpost认为，自从该公司在2018年首次发布其AI原则以来，该技术迅速发展。 “数十亿人在日常生活中使用了人工智能。 AI已成为一种通用技术，以及一个无数组织和个人用于构建应用程序的平台，” Hassabis和Monyika写道。 “它已经从实验室的利基研究主题转移到了一项技术这变得与手机和互联网本身一样普遍。一个对社会和世界各地的人都有许多有益用途的人，得到了开发人员的充满活力的AI生态系统的支持。 /05/google-owner-drops-promise-not-to-use-ai-for-weapons#:%7E:text=The%20Google%20owner%2C%20Alphabet%2C%20has,developing%20weapons%20and%20surveillance ％20TOOLS“&gt; https://www.theguardian.com/technology/2025/feb/05/google-wounder-wounder-wounder-drops-promise-promise-not-to-so--use-use-ai-for-weapons/ ％20 owner％2C％20Alphabet％2C％20HA，开发％20 weapons％20 and％20Surbhishance％20Tools 。  &lt;！&lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/aravrandg     [link]   ＆＃32;  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iiekzr/the_google_owner_owner_alphabet_has_has_has_has_dropped_its_promise/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</guid>
      <pubDate>Wed, 05 Feb 2025 16:52:02 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32; /u/u/automoderator     [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>