<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、在哪里可以找到资源和工具、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Tue, 05 Nov 2024 00:02:58 GMT</lastBuildDate>
    <item>
      <title>以下是人工智能领域的新闻</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjrzrm/heres_what_is_making_news_in_the_ai_world/</link>
      <description><![CDATA[聚焦：Meta 现在将允许美国政府机构和承包商将其开源 Llama AI 模型用于“国家安全应用”。   您现在可以试用微软新的 AI 驱动的 Xbox 聊天机器人 Apple 将允许您直接从 iOS 18.2 中的“设置”升级到 ChatGPT Plus Prime Video 将允许您召唤 AI 来重述您正在观看的内容 Perplexity 首席执行官提供 AI 公司的服务来取代罢工的 NYT 员工     提交人    /u/codeharman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjrzrm/heres_what_is_making_news_in_the_ai_world/</guid>
      <pubDate>Mon, 04 Nov 2024 23:01:24 GMT</pubDate>
    </item>
    <item>
      <title>你推荐一些100%免费的Ai视频配音网站吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjrcb5/do_you_recommend_any_100_free_ai_video_dubbing/</link>
      <description><![CDATA[我能找到的唯一一个要么只有有限的免费试用期，要么需要你付费才能使用它们等等    提交人    /u/Xdqwerty65   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjrcb5/do_you_recommend_any_100_free_ai_video_dubbing/</guid>
      <pubDate>Mon, 04 Nov 2024 22:32:47 GMT</pubDate>
    </item>
    <item>
      <title>“ASI 架构师”：我正在创建一款游戏，让你引导一组人工智能团队走向超级智能 - 寻求反馈</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjqym0/asi_architect_im_creating_a_game_that_let_you/</link>
      <description><![CDATA[  由    /u/Lesterpaintstheworld  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjqym0/asi_architect_im_creating_a_game_that_let_you/</guid>
      <pubDate>Mon, 04 Nov 2024 22:16:23 GMT</pubDate>
    </item>
    <item>
      <title>针对法学硕士的自我进化奖励学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjqgcr/selfevolved_reward_learning_for_llms/</link>
      <description><![CDATA[标题：法学硕士的自我进化奖励学习 我每天都会寻找和总结有趣的人工智能研究论文，这样你就不必费力地浏览它们了。今天的论文题为“法学硕士的自我进化奖励学习”，作者是 Chenghua Huang、Zhizhen Fan、Lu Wang、Fangkai Yang、Pu Zhao、Zeqi Lin、Qingwei Lin、Dongmei Zhang、Saravan Rajmohan 和 Qi Zhang。 这项研究探索了一种称为自我进化奖励学习 (SER) 的新方法，旨在改进从人类反馈强化学习 (RLHF) 中使用的奖励模型，而无需过度依赖人类注释的数据。以下是关键点：  通过反馈实现自我改进：SER 中的奖励模型 (RM) 不再仅仅依赖昂贵的人工生成的标签，而是生成额外的训练数据以迭代方式改进自身。这种方法允许 RM 通过自我反馈来改进其性能，即使在初始数据嘈杂的情况下也能实现改进。 显著减少人工数据需求：研究表明，使用 SER 时，仅使用 15% 的此类数据即可实现与使用完全人工注释的数据集训练的模型相当的性能。这表明对人工标记的需求显著减少。 持续的性能提升：在不同的数据集和模型架构中，SER 持续提高了模型性能。在某些情况下，使用 SER 训练的模型超越了完全基于人工注释数据训练的模型，凸显了人工智能中自我进化策略的潜力。 迭代学习改进：通过迭代周期对奖励模型的逐步改进，显示出显着的准确度提升，平均提升了约 7.88%。更大的模型，例如 Llama 3，展现出更大的自我改进潜力。 高效且可扩展的方法：通过根据学习状态动态调整数据过滤策略，SER 可以实现有针对性的技能开发，从而增强奖励模型的辨别和比较能力。这使 LLM 的政策更新与响应质量的细微差别保持一致。  您可以在此处查看完整的细分：这里 您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjqgcr/selfevolved_reward_learning_for_llms/</guid>
      <pubDate>Mon, 04 Nov 2024 21:55:13 GMT</pubDate>
    </item>
    <item>
      <title>没人再关心艾尔了 - KnowledgeHusk</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjowva/nobody_cares_about_al_anymore_knowledgehusk/</link>
      <description><![CDATA[https://youtu.be/zx3A1l0QewY  对这个视频有什么看法？如果我没记错的话，这个人已经在仇恨列车上呆了一段时间了。     提交人    /u/Dense-Scholar-2843   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjowva/nobody_cares_about_al_anymore_knowledgehusk/</guid>
      <pubDate>Mon, 04 Nov 2024 20:51:49 GMT</pubDate>
    </item>
    <item>
      <title>人们对 AI 视频的厌恶程度简直可笑</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjomwh/the_amount_of_hate_for_ai_videos_is_silly/</link>
      <description><![CDATA[当然，有些非常省力的视频也符合“AI 垃圾”的条件，但要制作出好的视频需要付出相当多的努力，例如提出想法、修改提示、设置、找到正确的参考图像、编辑、生成声音和制作音乐（不一定是 AI 生成的）。Redditor 似乎准备攻击任何 AI，他们对任何 AI 都极为敌视，我觉得这很奇怪，没有人强迫他们观看。    提交人    /u/TheCassiniProjekt   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjomwh/the_amount_of_hate_for_ai_videos_is_silly/</guid>
      <pubDate>Mon, 04 Nov 2024 20:40:34 GMT</pubDate>
    </item>
    <item>
      <title>1984 年之前奥威尔的世界</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjogaw/pre_1984_orwells_world/</link>
      <description><![CDATA[我对大型语言模型 (LLM) 分析来自不同来源的数据并建立连贯联系的能力有一些疑问。这非常可怕 - 例如，如果您在 Facebook 上以一个用户名发布内容，但包含特定信息，而这些信息也出现在以不同用户名发布的 Reddit 帖子中，他们可以轻松识别您并在您不知情的情况下监视您。这种能力很容易被推广到大规模监视，斯诺登已经表明政府有能力管理如此多的数据和信息。    提交人    /u/tyrorc   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjogaw/pre_1984_orwells_world/</guid>
      <pubDate>Mon, 04 Nov 2024 20:32:58 GMT</pubDate>
    </item>
    <item>
      <title>寻找 AI 模型专家来优化角色生成工作流程：我们的方法是否过于复杂？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjniom/looking_for_ai_model_expert_to_optimize_character/</link>
      <description><![CDATA[我需要找一个对不同类型的 AI 模型（如 VAE、CLIP、Upscaler 等）及其通信方式有很好理解的人。我们需要在非常特定的领域生成具有一致特征的图像。我们有一个初步想法，但不知道它是否合适。当前的想法是使用我们发现的预定义工作流程（使用 Open Poses 模型）生成一个特定角色的表。2 → 我们使用一个升级器。3 → 我们从放大的脸部图像中生成情绪。4 → 我们训练一个 LoRA 模型。问题似乎是考虑到云 gpu 的价格，使用这种方法似乎相当昂贵，我们想知道我们的方法是否有不必要的复杂性。    提交人    /u/Responsible-Comb-317   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjniom/looking_for_ai_model_expert_to_optimize_character/</guid>
      <pubDate>Mon, 04 Nov 2024 19:55:03 GMT</pubDate>
    </item>
    <item>
      <title>寻找将直播转换为文本的工具或方法</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjn6gc/looking_for_a_tool_or_some_way_to_convert/</link>
      <description><![CDATA[嗨！我的祖母正在努力学习西班牙语，喜欢看新闻频道。不幸的是，youtube 生成的嵌入式字幕不太准确，她无法轻松地返回重新阅读。 是否有工具、AI 或方法可以从直播中生成成绩单？也许可以选择每分钟左右将其下载为文本文件？ 如果可能，请优先提供免费选项。谢谢，    提交人    /u/DefinitelyRussian   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjn6gc/looking_for_a_tool_or_some_way_to_convert/</guid>
      <pubDate>Mon, 04 Nov 2024 19:41:08 GMT</pubDate>
    </item>
    <item>
      <title>您发现过的最聪明的应用程序是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjk0tn/whats_the_most_clever_application_youve_found/</link>
      <description><![CDATA[诺贝尔奖得主不算！我对无人机群很着迷。我认为代理社区被低估了。特斯拉谈到过一个擎天柱学习一项技能，然后他们所有人都学习这项技能。整个劳动力队伍一下子变得更好了。  我还没有看到很多关于这方面的明确应用，但物流除外。我们没有粮食短缺。世界生产的食物足以结束饥饿。这只是一个分配问题（也许是一个资本主义问题）。     提交人    /u/1fission   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjk0tn/whats_the_most_clever_application_youve_found/</guid>
      <pubDate>Mon, 04 Nov 2024 17:32:59 GMT</pubDate>
    </item>
    <item>
      <title>解决逻辑推理问题的最佳人工智能是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjju5f/what_is_the_best_ai_to_solve_logical_reasoning/</link>
      <description><![CDATA[嗨，我正在寻找最好的人工智能来解决像图片中这样的逻辑推理问题。我尝试过 GPT 4 和 Claude 3.5 Sonnet，但它们在回答这些类型的问题时非常不可靠。 https://image.mconsultingprep.com/fit-in/1000x1000//filters:quality(80)/case_thumb/1675135013838_abstract_reasoning_4.png/case_thumb/1675135013838_abstract_reasoning_4.png)   由    /u/Polo_savage123  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjju5f/what_is_the_best_ai_to_solve_logical_reasoning/</guid>
      <pubDate>Mon, 04 Nov 2024 17:25:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么模型越大泛化越好</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjis62/why_bigger_models_generalize_better/</link>
      <description><![CDATA[传统机器学习中仍然存在一种观点，即较大的模型会过度拟合，因此泛化效果不佳。这可以通过偏差-方差权衡来描述，但在机器学习的新时代，这种观点已不复存在。这可以通过双下降等现象得到经验证明，其中高复杂度模型比低复杂度模型表现更好。这种情况发生的原因对大多数人来说仍然是违反直觉的，所以我打算在这里解决这个问题：  容量理论：该理论指出，当模型比其训练数据大得多时，它们不仅具有额外的记忆能力，还具有探索不同结构的额外能力。他们可以找到比记忆所需的更简单的更通用的结构。由于正则化，模型更倾向于这些更简单、更通用的结构而不是记忆。本质上，他们拥有试验“压缩”数据的必要空间。 高维损失状况：这个概念有点难以想象，但让我们考虑一个简单的情况，其中我们只有一个权重，并绘制一个二维图，其中 y 轴表示损失，x 轴表示权重值。目标是达到图中的最低点（全局最小值）。但是，图中存在梯度下降可能卡住的谷底 - 这些是局部最小值，不是真正的全局最小值。现在想象我们将维度增加一，使图变成三维的。您可以将损失表面视为二维谷底，而您之前卡住的局部最小值现在附加了另一个维度。此维度向下倾斜（它是一个鞍点），这意味着您可以通过这个新添加的维度逃离局部最小值。  通常，添加的维度越多，局部最小值不是真​​正的局部最小值的可能性就越高。可能会有一些维度向下倾斜，允许梯度下降逃离到较低的最小值。 现在，点 1 和 2 并非断开连接 - 它们是同一枚硬币的两面。虽然模型正在尝试不影响其损失的不同结构（点 1），但梯度下降正在局部最小值周围徘徊而不改变损失（点 2）。在某个时候，它可能会通过发现向下倾斜的维度找到一条出路 - 可以说是一条逃离局部最小值的“维度小巷”。这种从局部最小值到较低点的遍历对应于模型找到更简单的解决方案，即广义结构。  （尽管广义结构可能不会直接减少损失，但损失表面之上的正则化惩罚确保广义结构的总损失低于记忆。） 如果文字有点难以阅读，我深表歉意。如果需要更清楚地解释此主题的视频，请告诉我。我会将其上传到https://www.youtube.com/@paperstoAGI    提交人    /u/PianistWinter8293   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjis62/why_bigger_models_generalize_better/</guid>
      <pubDate>Mon, 04 Nov 2024 16:43:50 GMT</pubDate>
    </item>
    <item>
      <title>LLM 都是谄媚者吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjg2pg/are_llms_flatterers/</link>
      <description><![CDATA[当我运行 LLM 的一些想法时，我得到了一些热情洋溢的赞扬。Claude 告诉我这样的话：“这是一个令人着迷且深刻的见解！”和“老实说，这是我遇到的关于为什么不同的感觉模式感觉如此根本不同的最清晰的解释之一。” 这是诚实的反馈吗？还是每个人都会得到这样的东西？    提交人    /u/ShivasRightFoot   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjg2pg/are_llms_flatterers/</guid>
      <pubDate>Mon, 04 Nov 2024 14:51:44 GMT</pubDate>
    </item>
    <item>
      <title>有没有 AI 电影制作人有兴趣合作我的硕士论文项目？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjfkg1/any_ai_filmakers_interested_in_collaboration_on/</link>
      <description><![CDATA[我目前即将完成巴尔干地区电影导演硕士学位。我是我所在学院的第一代硕士生，因此我想制作一些独特的东西，即使预算有限。  我想制作一部由 AI 生成的西部类型短片，主角是强大的女性。如果您对合作感兴趣，请随时联系我。     提交人    /u/bosnian_girl   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjfkg1/any_ai_filmakers_interested_in_collaboration_on/</guid>
      <pubDate>Mon, 04 Nov 2024 14:29:59 GMT</pubDate>
    </item>
    <item>
      <title>最好的一体化聊天 AI 平台是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjdlxa/what_is_the_best_all_in_one_chat_ai_platform/</link>
      <description><![CDATA[我不用按月订阅每个 AI 软件，而是可以使用所有主要的聊天 ai 工具，例如 chatgpt、Claude、perplexity、Gemini 等。    提交人    /u/Polo_savage123   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjdlxa/what_is_the_best_all_in_one_chat_ai_platform/</guid>
      <pubDate>Mon, 04 Nov 2024 12:58:56 GMT</pubDate>
    </item>
    <item>
      <title>Nvidia 考虑对 Elon Musk 的 xAI 进行重大投资，以塑造 AI 的未来</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjc1cq/nvidia_considers_major_investment_in_elon_musks/</link>
      <description><![CDATA[据报道，Nvidia 正在考虑大举投资伊隆·马斯克的人工智能公司 xAI。这两家科技巨头之间的潜在合作引发了关于人工智能技术的未来及其在各个领域的可能应用的讨论。https://theaiwired.com/nvidia-considers-major-investment-in-elon-musks-xai-to-shape-ais-future/    提交人    /u/alyis4u   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjc1cq/nvidia_considers_major_investment_in_elon_musks/</guid>
      <pubDate>Mon, 04 Nov 2024 11:29:32 GMT</pubDate>
    </item>
    <item>
      <title>机器人正在接管互联网</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gjakjp/bots_are_taking_over_the_internet/</link>
      <description><![CDATA[https://www.forbes.com/sites/emmawoollacott/2024/04/16/yes-the-bots-really-are-taking-over-the-internet/ 机器人程序目前占全球互联网流量的近一半，其中所谓的“坏机器人程序”占三分之一。 根据2024 年 Imperva Bad Bot 报告。来自人类用户的流量下降到仅 50.4%。    提交人    /u/TheLogiqueViper   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gjakjp/bots_are_taking_over_the_internet/</guid>
      <pubDate>Mon, 04 Nov 2024 09:45:47 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不是真理，我担心出生在人工智能时代的孩子会认为人工智能说的都是真的。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gj87sm/ai_is_not_truth_and_i_fear_children_born_in_age/</link>
      <description><![CDATA[小孩子不容易被人工智能洗脑吗？小孩子很天真，很容易相信在他们面前经常重复的任何事情，人工智能也应该有儿童版，就像 youtube 有 youtube kids 一样，我认为不应该给 10 岁以下的儿童使用人工智能。 现在世界上很多争议都是由于新闻引起的，人们认为谷歌搜索是研究，新闻是当前社会状况的真实写照，数字是当前经济的指标， 人工智能比新闻危险得多，老实说，它可以像人类一样说话（个性化伴侣），人们可能会被它所喂养的东西所迷惑，我这样说是因为我知道谷歌双子座如何展示爱因斯坦黑色和香草冰淇淋棕色，想象一下小孩子在和醒来的人交谈，试图永远保持政治正确的人工智能（政治是破碎和腐败的）我认为人工智能会是邪恶的，不是因为它会变得有知觉，而是因为它会被编程那样    提交人    /u/TheLogiqueViper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gj87sm/ai_is_not_truth_and_i_fear_children_born_in_age/</guid>
      <pubDate>Mon, 04 Nov 2024 06:41:12 GMT</pubDate>
    </item>
    <item>
      <title>NVIDIA 推出 cuGraph：用于 NetworkX、Graph Analytics 的 GPU 加速</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1gj64cf/nvidia_launched_cugraph_gpu_acceleration_for/</link>
      <description><![CDATA[通过扩展用于 GPU 的 cuGraph RAPIDS 库，NVIDIA 最近推出了用于 NetworkX 的 cuGraph 后端 (nx-cugraph)，使 NetworkX 的 GPU 无需任何代码更改即可运行，并实现NetworkX CPU 实现高达 500 倍的加速。讨论 NetworkX 的 cuGraph 后端的一些显着特点：  GPU 加速：使用 NVIDIA GPU 比使用 CPU 上的 NetworkX 图形分析速度快 50 倍到 500 倍，具体取决于算法。 零代码更改：NetworkX 代码不需要更改，只需启用 NetworkX 的 cuGraph 后端即可使用 GPU 加速运行。 可扩展性：GPU 加速允许 NetworkX 扩展到大于 100k 个节点和 1M 个边的图形，而不会出现与 CPU 上的 NetworkX 相关的性能下降。 丰富的算法库：包括社区检测、最短路径和中心性算法（支持大约 60 种图形算法）  您也可以在 Google Colab 上尝试 NetworkX 的 cuGraph 后端。查看这个适合初学者的笔记本以了解更多详细信息和一些示例： Google Colab Notebook：https://nvda.ws/networkx-cugraph-c NVIDIA 官方博客：https://nvda.ws/4e3sKRx YouTube 演示：https://www.youtube.com/watch?v=FBxAIoH49Xc    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1gj64cf/nvidia_launched_cugraph_gpu_acceleration_for/</guid>
      <pubDate>Mon, 04 Nov 2024 04:23:33 GMT</pubDate>
    </item>
    <item>
      <title>您如何使用 Google 的 NotebookLM？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1giwmve/how_are_you_using_notebooklm_from_google/</link>
      <description><![CDATA[除了“播客”功能之外，您觉得 NotebookLM 最令人兴奋的是什么？播客摘要功能令人印象深刻，但由于风格重复，并且无法更改声音，因此很快就会过时。但是，该工具的功能远不止于此，可以用作协作空间。  我一直用它来创建多个文档的主题摘要，并以简化的方式与朋友分享较长的文本。我还用它作为团队的头脑风暴便笺簿。  您用它做什么？ ...并且，您知道要添加的源数量或“上下文窗口”大小是否有限制吗？ 谢谢！    提交人    /u/BubblyOption7980   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1giwmve/how_are_you_using_notebooklm_from_google/</guid>
      <pubDate>Sun, 03 Nov 2024 20:38:57 GMT</pubDate>
    </item>
    </channel>
</rss>