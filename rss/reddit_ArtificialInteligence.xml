<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供门户，并促进有关我们所知的人工智能理念和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sat, 28 Dec 2024 00:03:26 GMT</lastBuildDate>
    <item>
      <title>CS</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnsffc/cs/</link>
      <description><![CDATA[您好，我想知道现在是不是获得计算机科学学士学位的好时机，然后再获得硕士学位来研究机器学习？我知道这是一个奇怪的问题，但我看到很多就业市场对这个领域的担忧，并且不想在毕业后为了找工作而负债累累。谢谢     提交人    /u/777Ando   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnsffc/cs/</guid>
      <pubDate>Fri, 27 Dec 2024 23:44:14 GMT</pubDate>
    </item>
    <item>
      <title>人工智能人性化器绕过人工智能检测器的可靠性如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnrxhx/how_reliable_are_ai_humanizers_for_bypassing_ai/</link>
      <description><![CDATA[在我看来，AI 人性化工具是绕过检测工具的最佳帮手。它们可以帮你节省数小时的句子挑选时间。但它们的效果如何？ BypassGPT：此工具是将 AI 文本转换为自然语言的最佳选择。你可以使用它来将专业或学术写作人性化。HIX Bypass：这个工具更高级一些，适合批量内容。它旨在提供与检测系统相媲美的性能。Humbot：Humbot 可以为你的作品增添一些趣味。它超越了重写，通过创建新的、类似人类的内容，非常适合论文或创意项目。Rewritify：简单但有效。它重新处理文本的清晰度和流程，提高整体可读性并降低检测风险。其他工具，如 Stealthy AI 和 PassMe AI，也有助于提高内容质量。您可以根据需要使用上述任何一种工具来绕过 AI 检测器。    提交人    /u/glutenbag   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnrxhx/how_reliable_are_ai_humanizers_for_bypassing_ai/</guid>
      <pubDate>Fri, 27 Dec 2024 23:20:27 GMT</pubDate>
    </item>
    <item>
      <title>大乐队模型：人机协作的交响框架</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnqcjs/the_big_band_model_a_symphonic_framework_for/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnqcjs/the_big_band_model_a_symphonic_framework_for/</guid>
      <pubDate>Fri, 27 Dec 2024 22:08:30 GMT</pubDate>
    </item>
    <item>
      <title>2025 年经纪人有何大事？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnq2t3/whats_the_big_deal_about_agents_in_2025/</link>
      <description><![CDATA[我知道什么是代理，以及它们通常有什么用处。但为什么现在对它们如此热衷？我们已经有了用于开发代理工作流程的框架/库，如 langchain、crewai、autogen 等。这可能在 2024 年甚至更早完成。  为什么所有大公司现在都开始谈论代理？     提交人    /u/Square_Poet_110   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnq2t3/whats_the_big_deal_about_agents_in_2025/</guid>
      <pubDate>Fri, 27 Dec 2024 21:56:29 GMT</pubDate>
    </item>
    <item>
      <title>融合 ChatGPT 与集成学习实现健康语料库中不连续命名实体识别</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnorgg/on_fusing_chatgpt_and_ensemble_learning_in/</link>
      <description><![CDATA[我每天都会查找和总结有趣的 AI 研究论文，这样你就不必费力地浏览它们了。今天的论文题为“关于在健康语料库中融合 ChatGPT 和集成学习进行不连续命名实体识别”，作者是 Tzu-Chieh Chen 和 Wen-Yang Lin。 本文通过将 ChatGPT 集成为集成学习中的仲裁者，探索了一种在健康相关数据集中进行不连续命名实体识别 (DNER) 的创新方法。传统上，由于文本中实体的碎片性，DNER 带来了重大挑战。认识到大型语言模型的潜力，作者将 ChatGPT 与五种最先进的 NER 模型相结合，以提高医学数据集的性能。以下是一些主要发现：  集成框架：该研究引入了一个框架，该框架将 ChatGPT 与五个 SOTA 模型结合使用，并使用自定义提示工程来更好地处理 DNER 任务的复杂性。 性能改进：通过在 CADEC、ShARe13 和 ShARe14 数据集上进行实验，该方法的 F1 分数比单个 SOTA 结果分别提高了约 1.13%、0.54% 和 0.67%，并且优于传统的投票集成方法。 生成式人工智能与集成学习：所提出的方法不仅超越了 GPT-3.5 和 GPT-4 的单独性能，而且还揭示了集成学习如何利用 ChatGPT 的功能在 NLP 任务中提供更准确、更可靠的结果。 精度和召回率：研究强调，尽管 ChatGPT 在召回率方面表现出色，但由于其生成性质，有时准确率较低，从而导致幻觉——这证明了在受控集成学习场景中使用它的价值。 资源效率：该方法值得注意的是利用集成框架内的现有生成模型，从而无需开发全新模型即可最大限度地利用现有计算资源。  您可以在此处查看完整的细分：这里您可以在此处查看完整的原始研究论文：Original论文    由    /u/steves1189  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnorgg/on_fusing_chatgpt_and_ensemble_learning_in/</guid>
      <pubDate>Fri, 27 Dec 2024 20:58:06 GMT</pubDate>
    </item>
    <item>
      <title>测量智力</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnnusq/measuring_intelligence/</link>
      <description><![CDATA[我发现一个非常有趣的话题，也是很少被提及的话题，就是定义、测量和验证“智力”等结构的实际过程。我想先介绍一些高层次的想法，让事情开始：  在心理学中，结构是一种理论实体，无法直接观察到，但可以从可测量的指标中推断出来。推断智力等结构的过程与机器学习中的潜在空间有相似之处 - 我们采用一组变量（例如测试项目）并使用降维技术来创建一组潜在向量/变量/因子。 这里的关键区别在于，心理结构需要建模和解释，因此观察到的变量通常使用因子分析等技术建模为这些看不见的变量的线性组合。定义智力的常见方法（如 g 因子）基于这些变量 - 流体智力、晶体智力、视觉感知均使用 FA 进行量化，事实上，查尔斯·斯皮尔曼最初就是为此目的开发了该方法。 您可以使用主成分分析生成类似于因子分析的潜在空间（假设使用了方差最大旋转），但与更复杂的方法（如使用自动编码器或 U-MAP）一样，PCA 旨在表示更紧凑空间中数据的方差。 用于测量智力的工具的“质量”是通过统计方式评估的。可靠性是通过查看测试的内部一致性和测试管理之间的一致性来评估的。效度有多种不同的定义，但从高层次来看，其目标是确定测试衡量了它所声称要衡量的构念，并与构念相关的结果相关联（智力应该与学业成绩有相当大的关联），并且它实际上与测试背景之外也有关联。 测试的实际组成通常通过对正确回答问题的概率进行建模来评估，该概率是个人能力的函数，包括某些潜在特征以及用于测量该特征的问题的难度等。这样做的目的是确定测试中的项目是否能有效区分不同能力水平的应试者 - 如果项目难度的分布过于均匀或稀疏，分数可能无法正确反映智力差异。   这里还有很多可以说的，有很多细微差别，但我主要想给出要点，以便我们可以谈论如何量化机器智能（并将其与人类进行比较）。 我认为这是相关的，因为关于像 O3 这样的模型在 ARC-AGI 等测试中的表现有很多讨论，而关于测试本身的表现的讨论相对较少。思考也很令人兴奋——我们知道如何以与人类认知相关的方式测量潜在特征，但目前我们才刚刚开始构思如何描述人工智能的内部运作。随着我们测量它的方式不断发展和变得更加完善，我们会发现什么？    提交人    /u/Murky-Motor9856   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnnusq/measuring_intelligence/</guid>
      <pubDate>Fri, 27 Dec 2024 20:17:32 GMT</pubDate>
    </item>
    <item>
      <title>有人参加过这个培训或者熟悉它吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnkyxf/has_anyone_taken_this_training_or_familiar_with_it/</link>
      <description><![CDATA[https://maven.com/alliekmiller/ai-for-business-leaders 或者他们会推荐一些类似的东西给她开始使用 AI 进行商业活动？    提交人    /u/seen_x   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnkyxf/has_anyone_taken_this_training_or_familiar_with_it/</guid>
      <pubDate>Fri, 27 Dec 2024 18:11:01 GMT</pubDate>
    </item>
    <item>
      <title>如今人工智能已经很普遍，而且人们依赖人工智能也存在风险，您认为如果人工智能停止工作或被完全禁止，会发生什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnkokh/now_that_ai_is_a_common_thing_nowadays_and_with/</link>
      <description><![CDATA[人工智能正在成为一种广泛使用的流行工具/资源，人们将其融入日常生活。而且速度超快。 凭借已经疯狂的能力，依赖人工智能的风险非常大。如果人工智能成为一种威胁，然后被禁止，你认为人们会如何反应？一些企业在没有人工智能的情况下会如何运作？ 然而，最大的问题是：你认为我们可以恢复正常吗？    提交人    /u/kmurrda   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnkokh/now_that_ai_is_a_common_thing_nowadays_and_with/</guid>
      <pubDate>Fri, 27 Dec 2024 17:58:57 GMT</pubDate>
    </item>
    <item>
      <title>我如何才能最大限度地利用 LLM 免费版本进行学校研究？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnj1ho/how_can_i_maximize_the_free_version_of_llms_for/</link>
      <description><![CDATA[我最近开始使用 Perplexity 为学校项目做研究。它非常有用，因为它为我提供了简短的摘要，然后我可以点击我认为有用的链接。但是，我觉得我没有充分利用免费版本。是否有任何提示我可以使用，例如，只使用带有 .edu 或 .gov 链接的网站？或者一般会使用学术上可靠的来源？您是否尝试过其他任何使研究过程更加高效的方法？    提交人    /u/TimeExplorer5463   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnj1ho/how_can_i_maximize_the_free_version_of_llms_for/</guid>
      <pubDate>Fri, 27 Dec 2024 16:47:31 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待可解释的人工智能？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnibdw/what_do_you_think_about_explainable_ai/</link>
      <description><![CDATA[今天，我们开始将 LLM 类型的 AI 融入到我们的产品和日常生活中。有些人强调，这些 AI 并没有真正地“思考”，因此有时会犯重大错误，例如幻觉。您认为这是一个重要问题吗？您将如何解决这个问题？    提交人    /u/MLannes   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnibdw/what_do_you_think_about_explainable_ai/</guid>
      <pubDate>Fri, 27 Dec 2024 16:15:37 GMT</pubDate>
    </item>
    <item>
      <title>人工智能如何理解我们（或者什么是嵌入）？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnfjoa/how_does_ai_understand_us_or_what_are_embeddings/</link>
      <description><![CDATA[有没有想过 AI 如何真正“理解”语言？答案在于嵌入——一种将单词映射到多维空间的强大技术。这使 AI 能够区分“光线很明亮”和“她有一个光明的未来”。 我写了一篇博客文章，通过示例直观地解释了嵌入的工作原理。希望你会喜欢它:) 完整博客文章的链接：https://open.substack.com/pub/diamantai/p/how-ai-understands-us-the-secret?r=336pe4&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=true    提交人    /u/Diamant-AI   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnfjoa/how_does_ai_understand_us_or_what_are_embeddings/</guid>
      <pubDate>Fri, 27 Dec 2024 14:04:27 GMT</pubDate>
    </item>
    <item>
      <title>机器人技术是否包含在“AGI”中（民意调查）？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnej79/is_robotics_included_in_agi_poll/</link>
      <description><![CDATA[我在几个论坛上看到过关于这个问题的辩论，所以我想我应该做一个简单的民意调查。  当然，我也想听听你做决定的理由。就我个人而言，我认为 AGI 不包括机器人技术，因为它只与智能本身有关，并不意味着机器人技术或任何物理的东西。 这只是我的意见，我很好奇大家怎么想！ 查看民意调查    由   提交 /u/Siciliano777   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnej79/is_robotics_included_in_agi_poll/</guid>
      <pubDate>Fri, 27 Dec 2024 13:09:53 GMT</pubDate>
    </item>
    <item>
      <title>AGI 前夕的思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hndnip/thoughts_on_the_eve_of_agi/</link>
      <description><![CDATA[完整帖子在此：https://threadreaderapp.com/thread/1871946968148439260.html Will Bryk 回顾了人工智能的快速发展，特别是 OpenAI 的 o3 模型，预测一年内数学、编码和推理能力将达到 AGI 水平。他预见到软件工程和数学等行业将受到变革性影响，而机器人技术和体力劳动自动化由于硬件挑战而滞​​后。Bryk 强调了社会不稳定、人工智能滥用和监管障碍等风险，但仍对科学、清洁能源和太空探索方面的突破持乐观态度。他强调，在这些前所未有的变化中，需要集体责任来确保积极的未来。    提交人    /u/C-levelgeek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hndnip/thoughts_on_the_eve_of_agi/</guid>
      <pubDate>Fri, 27 Dec 2024 12:15:44 GMT</pubDate>
    </item>
    <item>
      <title>国会在 2025 年国防授权法案中批准了人工智能立法 - 这对您有影响吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hndal4/congress_approved_ai_legislation_in_the_2025/</link>
      <description><![CDATA[最近批准的 2025 年国防授权法案中的任何 AI 条款是否适用于国防部以外？ 该法案： https://www.congress.gov/bill/118th-congress/house-bill/5009 摘要： https://natlawreview.com/article/congress-passes-defense-bill-ai-provisions-ai-washington-report?amp   由    /u/BubblyOption7980  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hndal4/congress_approved_ai_legislation_in_the_2025/</guid>
      <pubDate>Fri, 27 Dec 2024 11:51:46 GMT</pubDate>
    </item>
    <item>
      <title>Token Highlighter 检查并缓解大型语言模型的越狱提示</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hnaq12/token_highlighter_inspecting_and_mitigating/</link>
      <description><![CDATA[标题：Token Highlighter 检查和缓解大型语言模型的越狱提示 我每天都在寻找和总结有趣的 AI 研究论文，这样您就不必全部浏览一遍。今天的论文题为“Token Highlighter：检查和缓解大型语言模型的越狱提示”，作者是 Xiaomeng Hu、Pin-Yu Chen 和 Tsung-Yi Ho。 本文解决了大型语言模型 (LLM) 越狱攻击所带来的挑战，尽管使用强化学习人类反馈 (RLHF) 等技术进行了协调努力，但这种攻击仍有可能绕过安全机制。作者介绍了一种新方法 Token Highlighter，旨在检测和缓解这些攻击。 要点包括：  肯定损失概念：Token Highlighter 实现了一种称为肯定损失的独特方法，该方法量化了 LLM 对用户查询做出肯定响应的倾向，从而提供了一种指标来识别对越狱成功至关重要的令牌。 软删除技术：该方法不是完全删除关键令牌（称为硬删除），因为硬删除会妨碍良性查询的性能，而是采用“软删除”，巧妙地缩小令牌嵌入以减少其影响。 经验验证：通过对 LLaMA-2 和 Vicuna-V1.5 等对齐的 LLM 进行严格测试，Token Highlighter 展示了对各种越狱策略的强大防御能力，包括 GCG 和AutoDAN，同时保持对良性查询的高性能。 成本效益和可解释性：该方法既具有计算效率，只需要一个额外的查询，又具有可解释性，因为它突出显示了可疑标记以解释拒绝响应。 卓越的性能：与现有防御措施相比，Token Highlighter 在保持良性查询的高实用性的同时实现了较低的攻击成功率 (ASR)，标志着 LLM 安全性的重大进步。  您可以在此处查看完整的细分：这里您可以在此处查看完整的原始研究论文：原始论文    提交人    /u/steves1189   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hnaq12/token_highlighter_inspecting_and_mitigating/</guid>
      <pubDate>Fri, 27 Dec 2024 08:43:30 GMT</pubDate>
    </item>
    <item>
      <title>采用不切实际的时间表是怎么回事？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hn0hxq/whats_up_with_the_unrealistic_timelines_adoption/</link>
      <description><![CDATA[在关于 AGI 或 AI 的 XYZ 应用是否可行的争论中，人们忽略了一点，那就是有些人对 AI 的普及速度抱有荒谬的期望。无条件地说 AI 将取代医学博士是一回事，声称这将在 8-10 年内发生则是另一回事。我也看到有人争论说 25% 的技术工作将在 5 年内实现自动化，或者这将在 2025 年开始全面发生。 这里的问题不是它是否可能，而是你认为它会在你认为的时间范围内如何发生。人们似乎没有意识到在产品可行之前，在研究和开发之间需要多少来回，从概念验证到可行的产品需要多少工作，或者现有产品/解决方案/系统的广泛采用的现实时间表是什么样的。 为了讨论的方便，我们假设我们已经有了一个蓝图。您认为，融资物流和实际基于它生产产品的实际时间表是什么，清除人们开始使用它所需的任何评估，以及最终实现广泛采用的实际时间表是什么？    提交人    /u/Murky-Motor9856   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hn0hxq/whats_up_with_the_unrealistic_timelines_adoption/</guid>
      <pubDate>Thu, 26 Dec 2024 22:59:14 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmy0jz/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦：ChatGPT 和 Sora 本月第二次宕机 (TechCrunch)  微软向 OpenAI 投资近 140 亿美元，但现在它正在减少对 ChatGPT 母公司的依赖 (TechCrunch) AI 云初创公司 Vultr 在第一轮外部融资中筹集了 3.33 亿美元，融资额达到 35 亿美元 (Crunchbase) Heirloom 在繁忙的碳捕获融资年中获得 1.5 亿美元 (Crunchbase) DeepSeek 的新 AI 模型似乎是迄今为止最好的“开放”挑战者之一 (TechCrunch) 微软正在强迫人们使用其 AI 助手 (WSJ)  如果您想了解 AI 新闻，请首先在此处启动所有来源以及文章的完整摘要    由   提交  /u/codeharman   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmy0jz/heres_whats_making_news_in_ai/</guid>
      <pubDate>Thu, 26 Dec 2024 21:05:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能正在愚弄人类</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hms3w2/ai_is_fooling_people/</link>
      <description><![CDATA[人工智能正在愚弄人们 我知道这是一个有偏见的言论，我想很多人已经知道/相信了。 但最近我真的很受触动。我的家人 50 年来一直在帮助举办一个传统艺术音乐节。除了舞台设备和露营者便利设施外，一切都非常低技术。这是美国许多家庭喜爱的地方。我的祖父母是董事会成员，我父亲曾经是董事会主席。不用说，这个节日对我来说至关重要。董事会成员都是家人朋友和不懂技术的 Facebook 婴儿潮一代。他们嘲笑小黄人的表情包，并把它们打印出来给朋友看。 每年，他们都会举办年度标志艺术比赛。他们在 Facebook 上发布比赛结果并向获胜者支付奖金。我的祖父母在我家给我看明年的新标志……很明显，它是人工智能生成的。那是一把缺少琴弦的卡通吉他，人工智能甚至拼错了小镇的名字。这位“艺术家”解释说，他们只使用了一点人工智能，但大部分都是自己制作的。我不得不花两个小时告诉他们不能使用它，我不得不和所有董事会成员通电话，说服他们投反对票，因为使用人工智能生成的艺术作品作为传统艺术音乐节的标志，效果非常糟糕。他们无法理解，但最终在指出图片中的许多缺陷后，他们决定放弃它。  这位“艺术家”后来承认只使用了人工智能。董事会对人工智能一无所知，但舆论法庭不会在意，尤其是如果他们在衬衫和马克杯上出售这个标志。如果我的祖父母没有给我看，他们会用那个图像的。  人们还没有准备好接受人工智能。  编辑：我绝不是卢德分子。事实上，我很期待看到人工智能的发展方向以及它将如何改变我们的世界。我可能应该更好地解释这一点，但主要观点是，如果不披露其人工智能，人们就会被愚弄。我的家人一点也不笨，但他们年纪大了，技术超越了他们识别它的能力。我怀疑这种情况不会很快改变。天哪，他们中的一些人几乎不知道蓝牙是如何工作的。解释人工智能很难。     提交人    /u/Bishopkilljoy   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hms3w2/ai_is_fooling_people/</guid>
      <pubDate>Thu, 26 Dec 2024 16:38:58 GMT</pubDate>
    </item>
    <item>
      <title>我添加了专业人士的天赋</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</link>
      <description><![CDATA[由于最近对专业内容更加突出的兴趣，我认为一个好的开始是了解用户的哪些答案来自真正了解他们所谈论内容的人。 因此，我通过 mods 使经过验证的专业标签仅可分配。如果您想要该标签，您必须证明您在该领域工作。我把这留给您，我不在乎您的数据，并在看到后删除所有内容。如果您获得了标签，结果发现您对自己的职业撒了谎，无论出于何种原因，您都将被永久禁止，并且无法上诉。 一旦我们拥有足够多的人，我们还可以允许用户将某些帖子限制为仅供那些用户进行更专业的讨论。 让我知道您的想法    提交人    /u/ILikeBubblyWater   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hmc09x/i_added_flairs_for_professionals/</guid>
      <pubDate>Wed, 25 Dec 2024 23:49:53 GMT</pubDate>
    </item>
    <item>
      <title>每周“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hlffed/weekly_is_there_a_tool_for_post/</guid>
      <pubDate>Tue, 24 Dec 2024 15:09:09 GMT</pubDate>
    </item>
    </channel>
</rss>