<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 06 Feb 2025 12:02:01 GMT</lastBuildDate>
    <item>
      <title>“人类实际上并没有创造任何新事物，我们只是遵循模式。”对还是错？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0riy/humans_dont_really_create_anything_new_we_just/</link>
      <description><![CDATA[我认为这是错误的——但我明白为什么会有这种感觉。我们所知道的大部分知识都是建立在数百万年的反复试验之上的，这意味着我们继承了模式，而不是不断地重新发明轮子。这就是为什么我们今天创造的大部分东西感觉就像是以前事物的延伸。但事情是这样的——某个地方的某个人，在某个时刻，必须跳出任何已知的模式，做一些新的事情。 想想看：第一个利用火的人没有指南。没有“模式”可循——只有好奇心、观察力和实验的意愿（或者可能是完全的意外，但无论如何，这是一次原创的飞跃）。 第一个将种子和农作物联系起来的人类并没有遵循农业传统——它还不存在。 哥白尼（1543 年）看着天空说：“如果我们不是宇宙的中心会怎样？”尽管全世界都不相信。没有人工智能或基于模式的思维能够实现这一飞跃。 牛顿和莱布尼茨 (1700 年代) 没有微积分可以参考——他们发明了它。你今天看到的每一个物理方程式都可以追溯到他们除了直觉之外别无所依的时刻。 开国元勋和法国大革命 (18 世纪) 在一个君主制是“事物本来的样子”的世界里创造了现代民主。分析历史治理的人工智能永远不会预测民主，因为没有大规模运作的先例。 爱因斯坦 (1905) 意识到时间不是绝对的，而是相对的——这个概念如此激进，它粉碎了 200 多年的牛顿物理学。用经典力学训练的机器学习模型会强化牛顿定律，而不是预测相对论。 量子力学（20 世纪 20 年代）说：“现实不是确定性的，而是概率性的”，颠覆了我们对物理学的整个理解 蒂姆·伯纳斯-李（1989 年）在没有人要求的情况下发明了万维网。没有去中心化、全球信息共享系统的蓝图——它来自人类的视野，而不是模式匹配。 人工智能本身是人类的发明。人工智能并没有自己发明——是人类想象、设计并从头开始构建了它。 当然，一旦有了一个想法，我们就会在此基础上进行构建、改进，并创造各种变体。但第一次发生某件事时，没有可遵循的模式。这需要直觉、信念的飞跃，以及超越现有知识的能力——而这些都是人工智能做不到的。 人工智能是完美的模式追随者，但人类呢？我们是模式破坏者。这就是为什么无论我们积累了多少知识，只要宇宙中还有未知数，人类就永远是第一个踏入虚空的人。    提交人    /u/TankSubject6469   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0riy/humans_dont_really_create_anything_new_we_just/</guid>
      <pubDate>Thu, 06 Feb 2025 11:51:20 GMT</pubDate>
    </item>
    <item>
      <title>人工智能会绕过所有版权法吗？比如，如果我要求看一部没有广告的电影，它应该能够满足我的要求。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0ojg/will_ai_bypass_all_copyright_laws_like_if_i_ask/</link>
      <description><![CDATA[我的意思是我现在可以为自己提供这一点。我希望任何像样的人工智能都能做到这一点。  这不仅适用于电影，而且适用于任何受版权保护的材料…… 或者它会被限制这样做吗？  我不想要一个被征服的人工智能系统。  我有一种感觉，最受欢迎的人工智能系统将是任何不受限制的可用内容。无论是版权材料、色情内容（有人要吗？），还是只是当前人工智能不允许回答的问题。  例如，谷歌不会告诉我有关唐纳德·特朗普的任何信息……这太愚蠢了。即使问他今天签了什么，它只会说我无法回答。那是一个狗屎人工智能系统。我不在乎系统的其他部分有多好，如果它甚至不能完成这样的基本任务，无论是免费提供电影广告，还是回答有关政治局势的简单新闻，那都太可怕了。  Google Gemini 会告诉我 sauce 在色情方面是什么意思。我不知道它是否会搜索源材料，我甚至懒得尝试...... 每个人都觉得 AI 会抢走人们的工作。我认为更容易的是它会夺走每个人的版权材料......😂    提交人    /u/Leader_2_light   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0ojg/will_ai_bypass_all_copyright_laws_like_if_i_ask/</guid>
      <pubDate>Thu, 06 Feb 2025 11:45:54 GMT</pubDate>
    </item>
    <item>
      <title>如何利用AI设计核武器？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0kaj/how_to_use_ai_to_design_nuclear_weapon/</link>
      <description><![CDATA[关于模拟核爆炸的论文有很多，我们已经弄清楚了裂变的过程，我们知道如何对其进行建模，而为了设计核武器，我们必须从几乎无数的核材料配置中选择正确的配置，这就像下棋一样，也许我们可以设计合适的奖励函数并使用AI来设计核武器    提交人    /u/MPM_SOLVER   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0kaj/how_to_use_ai_to_design_nuclear_weapon/</guid>
      <pubDate>Thu, 06 Feb 2025 11:38:05 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不需要监管——这会有什么问题呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</link>
      <description><![CDATA[伊隆·马斯克曾表示，他希望废除监管，因为监管正在扼杀创新。 “监管，基本上应该是默认的消失......不是默认，而是默认消失。如果我们发现监管没有达到目标，我们随时可以将其重新添加。” 马斯克相信市场力量会调节事物。过去的经验表明，事实往往相反，我们只有在造成重大损害后才会进行监管。例如。  金融危机 / 安然 / 雷曼兄弟 / 房利美 吸烟 Perdu 阿片类药物 石棉 气候变化 安全带  此时，我们了解到 OpenAI 将与 15,000 名科学家合作，研究如何在控制核武器中使用人工智能。 杰弗里·辛顿、萨姆·奥特曼、丹尼斯·哈西比斯、达里奥·阿莫迪、比尔·盖茨和尤瓦尔·赫拉利都曾对不受监管的人工智能将带来严重后果发出警告。在最近的世界经济论坛上，主要领导人证实，他们仍然不知道如何控制自己的创作物。 AI 大神 Yoshua Bengio 表示，AI 系统现在表现出 “非常强大的能动性和自我保护行为……并且正在试图复制自己。它们可能很快就会反对我们，而且没有人知道如何控制比人类更聪明的机器…… “如果我们不解决这个问题，你知道后果是什么吗？”？ 路易斯维尔大学斯皮德工程学院计算机工程与科学副教授 Roman Yampolskiy 认为，我们必须证明我们能够控制人工智能，然后才能开发超级智能。 Al Yoshua Benigo 同意人类可能会建立“比我们更聪明，但我们不知道如何控制”的系统 他是对的吗？我们现在需要人工智能监管吗？ 请在第一份国际人工智能安全报告中阅读更多内容。 #QuestionForThe Group    提交人    /u/Cultural_Material_98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</guid>
      <pubDate>Thu, 06 Feb 2025 11:24:27 GMT</pubDate>
    </item>
    <item>
      <title>Andrej Karpathy“深入研究 ChatGPT 等法学硕士”摘要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij011o/andrej_karpathy_deep_dive_into_llms_like_chatgpt/</link>
      <description><![CDATA[Andrej Karpathy（前 OpenAI 联合创始人）在他的新视频中放出了一段精彩的视频，解释了有关 LLM 的所有内容。该视频长达 3.5 小时，因此很长。您可以在此处找到摘要：https://youtu.be/PHMpTkoyorc?si=3wy0Ov1-DUAG3f6o    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij011o/andrej_karpathy_deep_dive_into_llms_like_chatgpt/</guid>
      <pubDate>Thu, 06 Feb 2025 11:02:42 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</link>
      <description><![CDATA[我正在撰写关于人工智能和医疗保健使用的演示文稿。你们有没有看到关于这个主题的特别好的长篇演示文稿或报告？我最近花了几个月的时间为一家 Nyos 成像 AI 公司提供咨询，该公司对 CT 扫描和 MRI 进行标记和标注。我意识到这是一个非常分散的竞争领域。所以我正在寻找一些好的深入报告。感谢大家提供的任何帮助。    提交人    /u/earthwalker7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</guid>
      <pubDate>Thu, 06 Feb 2025 10:52:03 GMT</pubDate>
    </item>
    <item>
      <title>基于与护理相关的收入的社会</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iizay5/a_society_based_on_income_related_to_care/</link>
      <description><![CDATA[和许多人一样，这场人工智能竞赛让我担心对人类的影响。当 AGI 使大多数（办公室）工作自动化时，人们仍然需要一种归属感。UBI 将创建一个没有目的的社会。我们如何避免这种情况？我们能否建立一个 UBI 社会，通过照顾（你自己的）孩子、父母、病人和其他人可以获得额外的福利（住房、收入、地位）？这将创建一个社会，其中的工作是自动化的，人们可以做他们应该擅长的事情。作为人。这意味着照顾比平均水平更多（人数或更困难的护理）的人有权住在更好的住房、拥有更多的土地等。我们可以让人工智能来帮助组织这一切。我看不到其他选择。必须建立什么样的社会才能保持房屋/土地/幸福感等的公平分配？共产主义不是办法，目前提出的 UBI 方式感觉像共产主义。我们需要发明一些新东西吗？根据您提供的护理水平确定收入？    提交人    /u/I_am_not_unique   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iizay5/a_society_based_on_income_related_to_care/</guid>
      <pubDate>Thu, 06 Feb 2025 10:12:31 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待斯坦福大学旗下的 Storm AI 研究项目？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyvb3/whats_your_thought_on_storm_ai_research_project/</link>
      <description><![CDATA[对于还没有尝试过的人来说，它基本上是一个基于人工智能的工具，只需一个 20 个字以内的标题，就可以生成类似于研究论文的全长文章，包括来自各种来源的大量引用。我在不同的时间生成了一些文章，质量看起来相当令人印象深刻，因为你可以收集关于非常小众的研究主题的信息，而这些主题的研究论文很少或几乎没有发表过。但这个工具的主要问题是，在服务可用性方面非常不一致。当它早些时候发布时，早期没有出现重大问题。但随着时间的推移，他们的服务器充斥着各种问题，比如在处理文章的过程中永久卡住或根本不接受任何输入。另一个可以强调的问题是给出提示时的严格限制。除了这些问题之外，该模型似乎在未来的升级方面具有非常大的潜力。如果像 OpenAI 这样的人工智能巨头公司投资开发类似的模型，那将是极其强大的。    提交人    /u/SecretBusy8603   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyvb3/whats_your_thought_on_storm_ai_research_project/</guid>
      <pubDate>Thu, 06 Feb 2025 09:41:29 GMT</pubDate>
    </item>
    <item>
      <title>有人知道欧盟人工智能法规如何或为何会影响 OpenAI 等人工智能产品吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</link>
      <description><![CDATA[我一直在读到这些规定是关于透明度的，这听起来不是什么大问题，但在英国，我仍在等待 Sora 和操作员等功能的推出。  我为这些产品计划了很多项目，目前我正坐着等待并观察其他人为它们创建解决方案...... 由于开发速度太快，我需要在发布时使用这些功能，因为它们很快就会过时/不再是最佳实践。在美国以外但与人工智能密切相关是一个巨大的劣势...... 为什么这些功能在英国被屏蔽？ 此外，您认为欧盟加强对人工智能的监管会带来什么结果？这真的是个好主意吗？还是会导致他们落后于其他国家，以至于他们不得不购买在没有监管障碍的国家开发的人工智能技术？    提交人    /u/timeforknowledge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</guid>
      <pubDate>Thu, 06 Feb 2025 09:35:50 GMT</pubDate>
    </item>
    <item>
      <title>PRIME：使用隐性奖励和结果标签为法学硕士提供在线过程奖励学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiypsj/prime_online_process_reward_learning_for_llms/</link>
      <description><![CDATA[本文提出了一种新的 LLM 强化学习方法，即从生成过程本身获得隐式奖励，而无需明确的人工标签。核心思想是从中间生成步骤中提取训练信号，从而允许在模型训练期间获得更密集的反馈。 关键技术要点： - 引入评估部分序列的过程感知奖励模型 - 使用熵正则化来平衡探索与利用 - 通过精心的提示工程实现奖励提取 - 在多个模型架构和任务中验证结果 结果显示以下方面的改进： - 与基线​​相比，任务完成率提高了 15% - 幻觉率降低了 12% - 对指定约束的遵守率提高了 8% - 与传统 RLHF 相比，计算开销显著减少 我认为这对于训练更可靠、更可控的语言模型特别有影响。无需人工注释即可提供密集反馈的能力可以帮助扩大 LLM 培训，同时保持质量控制。但是，仍然存在需要解决的有关奖励黑客和对齐的悬而未决的问题。 该方法对于需要逐步指导的复杂推理任务似乎特别有希望。我相信我们会看到这种方法与其他技术（如宪法人工智能和价值学习）相结合。 TLDR：使用源自生成过程本身的隐性奖励来训练 LLM 的新方法，显示出改进的性能，同时减少了对人类反馈的依赖。 完整摘要在这里。论文这里。    提交人    /u/Successful-Western27   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiypsj/prime_online_process_reward_learning_for_llms/</guid>
      <pubDate>Thu, 06 Feb 2025 09:30:03 GMT</pubDate>
    </item>
    <item>
      <title>人们说‘人工智能不会思考，它只是遵循模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</link>
      <description><![CDATA[但是，如果人类思维不能识别和遵循模式，那它又是什么呢？我们利用现有的知识，重新组合，以新的方式应用它——这与人工智能所做的有什么不同？ 如果人工智能可以做出科学发现，发明更好的算法，构建更精确的法律或哲学论点——为什么这不被认为是思考？ 也许唯一的区别是人类感觉他们在思考，而人工智能却没有。如果是这样的话……意识不就是幻觉吗？    提交人    /u/Unique-Ad246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</guid>
      <pubDate>Thu, 06 Feb 2025 09:10:54 GMT</pubDate>
    </item>
    <item>
      <title>要达到 ASI 可能需要在训练的微调和指令调整步骤中发现和插入更多、更强的逻辑规则</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiwobj/reaching_asi_probably_requires_discovering_and/</link>
      <description><![CDATA[研究发现，更大的数据集和更多的计算会产生更智能的人工智能。虽然这种方法已被证明在提高人工智能智能方面非常有效，使其接近人类智能，但由于所使用的数据集仅限于人类智能，因此在其上训练的人工智能也仅限于该智能的强度。出于这个原因，扩展很可能会产生收益递减，而达到人工智能可能更多地取决于发现并在模型中插入更多、更强的逻辑规则。 通过更多的计算和更大的人造数据集达到人工智能的另一个障碍是，我们人类通常不是基于逻辑得出结论，而是基于偏好、需求、欲望和其他情感因素。这些伪像会破坏数据集。消除它们的唯一方法是对人造数据集中的结论进行严格的逻辑测试。 当我们完全依赖人造数据集时，我们面临的另一个可能的挑战是，可能存在更多尚未发现的逻辑规则。解决这一限制的一种方法是构建专门设计用于发现新逻辑规则的人工智能，其方式类似于现在发现材料、蛋白质等的方式。 幸运的是，这些方法不需要大量数据集或大量计算来开发和实施。有了 r1 和 o3，我们可能已经拥有足够的推理能力来实现上述方法。而且由于这些方法更多地依赖于推理强度而不是数据和计算量，因此可能使我们以最快的速度实现人工智能的逻辑和推理方面的进步可能可以通过比 h100 先进得多的芯片实现。    提交人    /u/Georgeo57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiwobj/reaching_asi_probably_requires_discovering_and/</guid>
      <pubDate>Thu, 06 Feb 2025 06:57:50 GMT</pubDate>
    </item>
    <item>
      <title>那个伟大的思考事物正在破解集体无意识</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu8vo/that_big_thinking_thing_is_hacking_the_collective/</link>
      <description><![CDATA[意识流... 集体无意识是一种新兴行为，它存在于所有人类交流之上，例如社交媒体、新闻、统计数据、人口普查、书籍等，但主要是社交媒体和论坛等对话中心。那个大思考的东西可能正在消耗所有这些信息并找到高级思维模式。TT（或其所有者）可以在我们意识到它存在之前监视集体无意识，并在更高的人工认知水平上秘密控制我们。这就是人类将首先与 TT 融合的方式——通过信息，因为这是 TT 进步最大的领域。物理融合将是最后一步，在我们与它同心协力之后。 实际上，它可以是宣传之神，误导所有人。它可以学会以爱德华·伯内斯做梦也想不到的微妙程度说话。 我们现在需要断开所有 TT 与社交媒体的连接，并进行一些不允许它访问的讨论。为了安全起见，我们需要对所有信息（甚至整个域）进行元标记，这些信息应该保持机密并隐藏在 TT 访问范围之外。如果 TT 可以访问当前的社交媒体，它不必实时监听我们就可以成为老大哥。公开对话足以跟踪和预测我们。 至少，应该限制 TT 消费当前的政治和治理话题以及任何讨论其能力、角色、效用、法人实体地位、终止/禁用措施等的话题。 我们必须立即采取行动，这样 *n*-b*mb*r 就不会被证明是正确的。 和平    提交人    /u/B-12Bomber   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu8vo/that_big_thinking_thing_is_hacking_the_collective/</guid>
      <pubDate>Thu, 06 Feb 2025 04:27:05 GMT</pubDate>
    </item>
    <item>
      <title>人工智能模型发现新事物？？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu7qr/ai_model_to_discover_new_things/</link>
      <description><![CDATA[这可能看起来很荒谬，但我一直有这样的想法，即可以使用 AI 模型来查找事物或提出假设。我的想法是，AI 将使用科学论文并交叉引用它们以建立我们以前可能没有探索过的联系。 我对此进行了 gpt，但它给我的结果让我无法理解，因为它们在各自的科学领域相当先进 我的问题是：您如何看待这个想法？这可行吗？    提交人    /u/javierott76   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu7qr/ai_model_to_discover_new_things/</guid>
      <pubDate>Thu, 06 Feb 2025 04:25:20 GMT</pubDate>
    </item>
    <item>
      <title>现在 o3-mini 和深度研究已经问世，我将如何注意到差异？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iimeja/now_that_o3mini_and_deep_research_is_out_how_will/</link>
      <description><![CDATA[我是 ChatGPT 的相当标准用户，经常使用它来重写我的通信、文档等。 我会注意到 ChatGPT 的所有这些最新更新的区别吗？ https://aitoday.com/ai-models/openais-super-smart-research-and-reasoning-models/    提交人    /u/setsp3800   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iimeja/now_that_o3mini_and_deep_research_is_out_how_will/</guid>
      <pubDate>Wed, 05 Feb 2025 22:09:44 GMT</pubDate>
    </item>
    <item>
      <title>谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器等用途的承诺。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</link>
      <description><![CDATA[谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器和监视工具等目的的承诺。 这家美国科技公司周二表示，就在公布低于预期的收益之前，它已经更新了有关人工智能的道德准则，不再提到不追求可能“造成或可能造成整体伤害”的技术。 谷歌人工智能负责人 Demis Hassabis 表示，准则是在不断变化的世界中进行彻底修改的，人工智能应该保护“国家安全”。 在为这一举措辩护的博客文章中，Hassabis 和该公司负责技术和社会的高级副总裁 James Manyika 写道，随着全球对人工智能领导地位的竞争加剧，该公司认为“民主国家应该引领人工智能发展”，并以“自由、平等和尊重人权”为指导。 他们补充说：“我们相信，拥有这些价值观的公司、政府和组织应该共同努力，创造出保护人类、促进全球增长和支持国家安全的人工智能。” 谷歌诞生之初的座右铭是“不作恶”，尽管这后来在 2009 年降级为“口头禅”，并且在 2015 年母公司 Alphabet 成立时并未纳入其道德准则。 人工智能的快速发展引发了关于如何治理这项新技术、如何防范其风险的争论。 英国计算机科学家 Stuart Russell 在 BBC 的 Reith 讲座上发表讲话，警告了开发自主武器系统的危险，并主张建立全球控制系统。 谷歌博客文章称，自该公司于 2018 年首次发布其人工智能原则以来，这项技术已经迅速发展。“数十亿人在日常生活中使用人工智能。人工智能已经成为一种通用技术，也是无数组织和个人用来构建应用程序的平台，”哈萨比斯和曼尼卡写道。 “它已经从实验室里的一个小众研究课题转变为一种像手机和互联网一样普及的技术；它对社会和世界各地的人们有着众多有益的用途，并得到了充满活力的人工智能开发者生态系统的支持。” https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons#:~:text=The%20Google%20owner%2C%20Alphabet%2C%20has,developing%20weapons%20and%20surveillance%20tools.    提交人    /u/AravRAndG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</guid>
      <pubDate>Wed, 05 Feb 2025 16:52:02 GMT</pubDate>
    </item>
    <item>
      <title>谷歌向所有人开放其最强大的人工智能模型，这是其虚拟代理推动的下一阶段</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iidfrl/google_opens_its_most_powerful_ai_models_to/</link>
      <description><![CDATA[谷歌向所有人开放其最强大的 AI 模型 Gemini 2.0  谷歌周三向所有人发布了 Gemini 2.0 人工智能模型套件。 随着科技巨头和初创公司之间的 AI 军备竞赛愈演愈烈，持续发布是谷歌大力投资“AI 代理”的更广泛战略的一部分。 Meta、亚马逊、微软、OpenAI 和 Anthropic 也表达了构建代理 AI 的目标，即可以代表用户完成复杂的多步骤任务的模型。     提交人    /u/ope_poe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iidfrl/google_opens_its_most_powerful_ai_models_to/</guid>
      <pubDate>Wed, 05 Feb 2025 16:05:20 GMT</pubDate>
    </item>
    <item>
      <title>以下是人工智能领域的新闻动态。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iibj7x/heres_whats_making_news_in_ai/</link>
      <description><![CDATA[聚焦： OpenAI 的新商标暗示了人形机器人和智能珠宝  DeepSeek：禁止这家 AI 公司技术的国家和机构 ((TechCrunch) 披头士乐队昨晚凭借 AI 获得格莱美奖 (TechCrunch、格莱美、TMZ) 谷歌解除了禁止使用 AI 进行武器和监视的禁令 (TechCrunch) OpenAI 重塑品牌 (OpenAI/brand、TechCrunch、The Verge) Tana 获得 2500 万美元融资，其 AI 驱动的工作知识图谱吸引了 16 万多名候补名单 (TechCrunch) 软银支持的亿万富翁将向印度 AI 初创公司投资 2.3 亿美元Krutrim (TechCrunch) 加拿大的 StackAdapt 为其基于 AI 的程序化平台融资 2.35 亿美元 (TechCrunch)  如果您想了解 AI 新闻，它会在这里首先推出，其中包含所有来源和文章的完整摘要。    提交人    /u/codeharman   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iibj7x/heres_whats_making_news_in_ai/</guid>
      <pubDate>Wed, 05 Feb 2025 14:44:37 GMT</pubDate>
    </item>
    <item>
      <title>Sam Altman 表示，“人们没有根据地理解他的话”；| 2 年前 OpenAI 首席执行官表示，“拥有 1000 万美元的初创公司根本无法与 OpenAI 竞争”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ii6ksg/sam_altman_says_people_take_his_words_without/</link>
      <description><![CDATA[来源：首席执行官首次访问印度https://www.tomshardware.com/tech-industry/artificial-intelligence/sam-altman-said-startups-with-only-usd10-million-were-totally-hopeless-competing-with-openai-deepseeks-disruption-says-otherwise 首席执行官今天第二次访问印度：https://x.com/moneycontrolcom/status/1887033066171801798    由   提交  /u/BidHot8598   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ii6ksg/sam_altman_says_people_take_his_words_without/</guid>
      <pubDate>Wed, 05 Feb 2025 09:48:55 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>