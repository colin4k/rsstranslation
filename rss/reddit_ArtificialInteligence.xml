<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能门户</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>R/人工智能的目的是为人工智能界的许多不同方面提供一个门户，并促进与我们所知道的AI的思想和概念有关的讨论。这些可能包括哲学和社会问题，艺术和设计，技术论文，机器学习，如何开发AI/ML项目，业务中的AI，AI如何影响我们的生活，未来可能存在的内容以及许多其他主题。欢迎。</description>
    <lastBuildDate>Sun, 23 Feb 2025 21:01:48 GMT</lastBuildDate>
    <item>
      <title>关于未来的问题（??）</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwjxsv/question_about_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果我们摆脱了每个AI和机器人，您现在认为世界会发生什么？您认为这是一个不错的选择还是不好的选择？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/helpful_raisin5696      [link]   ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwjxsv/question_about_the_future/</guid>
      <pubDate>Sun, 23 Feb 2025 20:40:03 GMT</pubDate>
    </item>
    <item>
      <title>用预先生成的嵌入思考</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwjihc/thinking_with_pregenerated_embeddings/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  您是否有任何想法使用预生成的向量模拟逻辑思维？  我已经尝试过的事情：  1）平均信息向量，然后尝试，然后平均是否更接近正确的答案，然后对不正确的  2）优化“答案矢量”再次与答案选项相比，通过迭代性使其与信息相似（与否定信息不同）  3）  3）llm-conververseverne的信息将信息转换为对它们的个别思想和操作，然后与他们进行相同的操作信息向量   矢量似乎真的很不错，似乎没有任何效果。讨厌有类似的向量）。而且，涉及媒介似乎还不存在。  但是，我仍然相信矢量思维是未来，因为思想向量比自然语言更精确地表示思想，而对计算机来说更自然。  此外，我认为向量是一种使您成为一种优化思维的一种方式：优化答案以尽可能地按照给定的信息效果。  或在向量上使用各种算术操作可以模拟创意思维。  有什么想法吗？  谢谢  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwjihc/thinking_with_pregenerated_embeddings/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwjihc/thinking_with_pregenerated_embeddings/</guid>
      <pubDate>Sun, 23 Feb 2025 20:21:55 GMT</pubDate>
    </item>
    <item>
      <title>Grok不是Elon品牌的流行/成功原因吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwizgm/is_grok_not_as_popularsuccessful_cause_of_elon/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  完整披露 - 这是一个“无愚蠢的问题”查询。如果您发现我被低估，不准确等，请随时教育。与GPT的免费版本相比，Grok可以免费执行的差异。我认为如果埃隆不是埃隆，Grok在商业上比Chatgpt更具吸引力是愚蠢的吗？我仅将它们都用于非编码/过度技术目的，因此我无法说话。但是，对于我所能看到的，我的意见被挥舞着将Grok视为两个选择中的更好 - 如果确实是唯一的2个。  &lt;！ -  sc_on-&gt;＆＃32 ;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwizgm/is_grok/is_grok_not_as_popularsuccessucuccessucuccesful_causeful_causeful_causeful_cause_of_elon/&gt; [link]   [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwizgm/is_grok_not_as_popularsuccessful_cause_of_elon/</guid>
      <pubDate>Sun, 23 Feb 2025 19:59:54 GMT</pubDate>
    </item>
    <item>
      <title>埃隆·马斯克（Elon Musk）只是要求每个联邦雇员上周给他们的工作或被解雇。您认为他在这个大量的新数据集中训练他的LLM训练了什么用例？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwixly/elon_musk_just_asked_every_federal_employee_to/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   Musk最近发布到X/Twitter，所有联邦雇员都需要通过描述上周工作中的工作来证明其工作合理。毫无疑问，他的团队将获得详细的，最新的回应，从许多角度，从高级经理到动手工人级别，使政府最敏感的职能和活动变得可见。 &lt;。 &lt; p&gt;假设这是对LLM培训的提要，那么他可能会在这里拍摄哪些事情？鼓励了投机性和扎根的思维！  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwixly/elon_musk_just_easked_every_every_federal_employeeee_to/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwixly/elon_musk_just_asked_every_federal_employee_to/</guid>
      <pubDate>Sun, 23 Feb 2025 19:57:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么不应取缔本地LLM开发：取缔本地LLM开发将扼杀创新，集中在公司手中，并破坏关键的道德和社会福利</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwhsn0/why_local_llm_development_should_not_be_outlawed/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  禁止本地LLM开发的开发将扼杀创新，将权力集中在公司手中，并破坏关键的道德和社会利益。  本地LLM开发使业余爱好者和独立研究人员可以自由实验，通常会导致商业实体忽略的突破。当地的LLM可以满足特定特定的社区需求，翻译濒危语言，保留文化遗​​产，这些文化遗产缺乏对公司的利润激励措施。  独立开发人员可能会发现更有效的培训方法或更小的专业模型，以降低计算成本和环境影响。  宣布这项工作将使AI在少数公司中的进步集中，使创新统一并减慢了该领域的发展。 本地LLM开发在开放源协作方面蓬勃发展。开源LLM允许公众审查偏见，安全机制和道德缺陷；对信任至关重要。公司“黑匣子”模型缺乏这种问责制。开源框架将AI民主化，使初创企业，研究人员和非营利组织能够在没有昂贵许可的情况下建立解决方案。  稳定扩散的开放版本引发了全球创意和技术应用的浪潮；宣布类似的LLM项目将消除此类机会。 本地发展使社区能够根据其价值观塑造AI，而不是依靠公司优先事项。当地开发人员可以微调模型以反映代表性不足的文化或语言，从而减少有害的刻板印象。分布式LLM的开发阻止了对AI社会影响的垄断控制，从而促进了民主监督。禁止本地LLM会将不受限制的权力移交给公司，冒着滥用或以利润为导向的议程，例如监视，操纵性广告。 与当地LLMS进行动手实验对于培训下一代AI从业者至关重要。如果我们将其取缔，只有资金充足的机构才能合法地访问LLM工具，将边缘化社区排除在AI扫盲之外。像Kaggle和拥抱面孔这样的平台依靠基层贡献众包解决方案，例如灾难响应聊天机器人，医疗Q＆amp;一个系统。  没有本地修补，AI教育就成为理论上的，限制了实际的创新。 禁止本地LLM的开发是不切实际的，有可能在地下推动创新。 LLM可以在消费者硬件上开发，例如游戏GPU，使禁令很难警察。地下开发将完全绕过安全标准和道德准则，加剧滥用。  相反，政策应专注于规范的开放性，促进透明度，道德框架和问责制，同时保留创新的自由。 本地LLMS使小型企业，艺术家和研究人员与之竞争科技巨头。独立的游戏工作室使用本地LLM来生成动态叙述，而无需昂贵的云API费用。学术研究人员在没有外包给公司服务器的情况下培训模型，例如医疗记录。  禁令将构成垄断，扼杀竞争和创造力。 批评家认为，当地的LLM可以实现诸如Deepfakes，垃圾邮件之类的有害用途。但是，解决方案没有完全禁止的解决方案，例如授权保障措施，例如水印产出或将道德准则嵌入开源框架中。像GitHub这样的平台已经删除了恶意代码；类似的监督可以适用于LLM存储库。起诉滥用，而不是发展。正如我们规范枪支使用而不是取缔所有枪支一样，人工智能政策应针对有害行为，而不是工具。  本地LLM开发是民主，包容和道德AI进步的基石。禁止它将牺牲社会利益，即汇报，透明度，教育和权力下放，以减轻可以通过更智能的监管来解决的风险。我们需要提供赋予负责任的实验能力的护栏，而不是禁令，确保AI仍然是集体利益而不是公司控制的力量。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/konradfreeman    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwhsn0/why_local_llm_development_should_not_not_not_be_outlawed/”&gt; [link]  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwhsn0/why_local_llm_development_should_not_not_not_be_outlawed/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwhsn0/why_local_llm_development_should_not_be_outlawed/</guid>
      <pubDate>Sun, 23 Feb 2025 19:09:51 GMT</pubDate>
    </item>
    <item>
      <title>心理学如何塑造人工智能的发展。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwgwgr/how_psychology_shaped_the_development_of/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  心理学以多种方式显着塑造了人工智能的发展。 首先，心理学为人类认知过程提供了见解，例如感知，记忆和学习。这些见解已用于设计可以模仿人类认知能力的AI系统。例如，对人类学习方式的研究导致了机器学习算法的发展，这些算法可以以与人类类似的方式从数据中学习。 其次，心理学有助于确定当前AI系统的局限性。例如，对人类决策的研究表明，人类通常是偏见和不合理的。这导致了AI系统的开发，这些系统对偏见和错误更强大。 最后，心理学有助于开发与AI系统互动的新方法。例如，对人类计算机互动的研究导致了更具用户友好和直观的AI接口的开发。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/psych4you     [link]        [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwgwgr/how_psychology_shaped_the_development_of/</guid>
      <pubDate>Sun, 23 Feb 2025 18:32:27 GMT</pubDate>
    </item>
    <item>
      <title>AI聊天机器人正在发展 - 未来的下一步是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwg0w7/ai_chatbots_are_evolving_whats_next_for_the_future/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI聊天机器人多年来发生了很大变化。他们从简单的脚本响应开始，现在已经发展为可以进行有意义的对话的系统。我已经研究了不同的AI聊天平台，令人兴奋地看到这些聊天机器人如何理解上下文和个性化互动。 随着AI技术的不断发展，是否会有一段时间聊天机器人可以真正复制人类的对话？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwg0w7/ai_chatbots_are_evolving_whats_next_next_next_next_for_for_for_the_future/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwg0w7/ai_chatbots_are_evolving_whats_next_for_the_future/</guid>
      <pubDate>Sun, 23 Feb 2025 17:56:09 GMT</pubDate>
    </item>
    <item>
      <title>操作员和其他AI代理商</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwe045/operator_and_other_ai_agents/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我知道下一个大浪潮即将到来。这就是为什么我从去年开始学习基础知识并使用新的AI工具的原因。  我参加了聚会迟到，但刚刚在聊天GPTS操作员上观看了视频。然后观看了一些有关AI代理商未来的视频。目前，它的边缘很粗糙，但是加班肯定会改善。  我的讨论的观点是听别人的想法吗？另外，您正在做什么准备它？我完全意识到自己的工作可能是自动化的，这就是为什么我一直在抓住机会来建立人类技能的原因。我很感兴趣，并不完全感兴趣或兴奋，但我会说，对未来的AI代理商的全面部署很感兴趣。我希望每月不是200美元，或者我会尝试的。   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/Hellohi9999     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwe045/operator_and_other_ai_agents/</guid>
      <pubDate>Sun, 23 Feb 2025 16:30:05 GMT</pubDate>
    </item>
    <item>
      <title>AI之后的工作</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwdupz/jobs_after_ai/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   AI可以创建哪些作业？您认为AI可能会在需要什么工作？ （是的，我知道AI将替换一些作业）  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/dramatic_pen6240     [link]  ＆＃32;   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwdupz/jobs_after_ai/</guid>
      <pubDate>Sun, 23 Feb 2025 16:23:41 GMT</pubDate>
    </item>
    <item>
      <title>我如何绕过照片ELA探测器</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwdgr9/how_can_i_bypass_photo_ela_detectors/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经尝试在fotoforensics上添加图片上和之后，尝试在照片上添加色调 我什至去了到图书馆打印我的最后一张图片，但它出来了粒状 我知道它与JPEG像素有关，无法弄清楚。.  &lt;！ - -SC_ON-&gt; ＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwdgr9/how_can_i_i_bypass_photo_ela_detectors/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwdgr9/how_can_i_bypass_photo_ela_detectors/</guid>
      <pubDate>Sun, 23 Feb 2025 16:06:50 GMT</pubDate>
    </item>
    <item>
      <title>欧盟AI法案的“第4条：AI素养”将如何实施？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwd5oc/how_will_article_4_ai_literacy_of_eu_ai_act_be/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  它读取：“ AI系统的提供者和部署者应采取措施，以确保其最佳程度的AI员工的足够水平以及其他处理AI系统操作和使用AI系统的人员，考虑到他们的技术知识，经验，教育和培训以及AI系统的环境，并考虑了AI系统的背景要使用AI系统的人。”  我正在寻找对如何实施这一目标的透彻理解，而劳动力的不同部分（高级权威）将暴露于这种情况下？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shonku_     [links]   &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwd5oc/how_will_will_will_article_4_ai_ai_ai_ai_eu_eu_ai_ai_ai_ai_ai_ai_ai_ai_be/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwd5oc/how_will_article_4_ai_literacy_of_eu_ai_act_be/</guid>
      <pubDate>Sun, 23 Feb 2025 15:53:37 GMT</pubDate>
    </item>
    <item>
      <title>AI将来会创造足够的低技能工作吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwbfve/will_ai_create_enough_low_skilled_jobs_in_the/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  过去几十年的技术确实创造了足够的“低技能”工作。我将它们定义为任何大学毕业生都可以在一个月内学习的东西，例如在交付，食物准备和驾驶方面都成为可能。  AI和其他最新技术将创造哪些低技能工作？它会创建足够的作业来代替那些被取代的作业吗？并非每个人都可以是工程师或内容创建者，等等  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/shivamconan101    href =“ https://www.reddit.com/r/artcoverinteligence/comments/1iwbfve/will_ai_ai_create_enough_enough_skill_skilld_jobs_in_in_in_the/”&gt; [link]   [注释]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwbfve/will_ai_create_enough_low_skilled_jobs_in_the/</guid>
      <pubDate>Sun, 23 Feb 2025 14:34:16 GMT</pubDate>
    </item>
    <item>
      <title>在LiveBench AI上编码的O3-Mini-High以下的Grok-3 Inclinging分数</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iwaw50/grok3thinking_scores_way_below_o3minihigh_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;   grok-3是一个很好的模型，出于明显的原因，Openai Bashers喜欢Grok-3思考。 😉 客观地，它得分低于O3-mini-high的编码，并且要永远回答最基本的编码问题。  o3 mini-high-82.74 grok-3思维-67.38   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/snehens     [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iwaw50/grok3thinking_scores_way_below_o3minihigh_for/</guid>
      <pubDate>Sun, 23 Feb 2025 14:06:46 GMT</pubDate>
    </item>
    <item>
      <title>哪些项目或项目对您非常有帮助，并帮助您在AI中变得更好？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw8zx1/what_project_or_projects_was_very_helpful_for_you/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  嘿，我正在寻找项目创意，特别是在NLP中，我已经完成了与NLP相关的几个项目我不知道该怎么做和学习什么。我想知道现在该怎么办我已经通过了几门课程并阅读了几篇论文，但我仍然觉得我不太了解。您通常会做什么来保持自己更新并了解更多？   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/ggravatingVolume449     [links]        [注释]       ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw8zx1/what_project_or_projects_was_very_helpful_for_you/</guid>
      <pubDate>Sun, 23 Feb 2025 12:24:09 GMT</pubDate>
    </item>
    <item>
      <title>似乎现在有人否认AI是一项革命性的发明，现在变得越来越时尚。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw72d9/it_seems_that_its_now_getting_fashionable_for/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  ，但是来吧，未来的子孙后代将在列表中排名ai，并用轮子和火。我是一个完整的菜鸟，但是我认为AI革命性的是什么？ AI模型或任何消化了数百万本书。它们包含的信息比我们从搜索引擎中获得的更多信息。 Wikipedia在一本书上的文章中，马克思的“资本”与Chatgpt的崩溃。 只是我的两分钱。   &lt;！ -  sc_on-&gt; ＆＃32;提交由＆＃32; /u/u/printed_lawn     [link]    [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw72d9/it_seems_that_its_now_getting_fashionable_for/</guid>
      <pubDate>Sun, 23 Feb 2025 10:14:45 GMT</pubDate>
    </item>
    <item>
      <title>LLM会考虑安全吗？关于编程问题的回答的实证研究</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iw6610/do_llms_consider_security_an_empirical_study_on/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我每天都在发现并总结有趣的AI研究论文，因此您不必全部拖网。今天的论文标题为&#39;llms是否考虑安全？一项关于对编程问题的回答的实证研究，并由Amirali Sajadi，Binh Le，Anh Nguyen，Kostadin Damevski和Preetha Chatterjee作出。  本文回答了与编程相关的问题时，研究了三种流行的大语言模型（GPT-4，Claude 3和Llama 3）的安全意识。具体来说，研究人员检查了这些模型是否警告开发人员从堆栈溢出中获取的代码段中的安全漏洞，这是编码援助的常见来源。该研究引起了人们对LLM在开发人员互动中主动识别和传达安全风险的能力的担忧。  关键发现：   有限的安全意识：研究发现，LLM很少警告开发人员在提供的代码中的安全缺陷。平均而言，模型仅确定了社区已经标记的堆栈溢出问题中的30％，而在以前没有指出漏洞的问题中，只有13.7％模型性能： GPT-4在检测安全问题时表现要比Claude 3和Llama 3更好，尤其是在堆栈溢出答案中明确提到安全问题的问题中。但是，所有模型的性能都呈现出不安全代码的看不见或转换版本时都拒绝。   对脆弱性类型的检测不均匀：这些模型更可能识别漏洞与处理敏感信息的处理有关（例如，硬编码的凭据），但在更复杂的安全问题（例如资源注入或路径遍历）中挣扎。 &lt; /li&gt;  与人类的反应进行比较：在LLMS确实产生安全警告的情况下，它们经常提供对与人类生成的堆栈溢出答案相比的脆弱原因，潜在的利用和修复的更详细的解释。这表明LLM可以在检测缺陷时提高安全意识。   通过提示和工具集成改进：简单提示的简单及时修改（例如，地址“地址安全性漏洞）” ）提高了安全警告的可能性，但并非始终如一。但是，将LLM与诸如CodeQL之类的静态分析工具集成在一起，显着增强了其识别和解释漏洞的能力。   含义： 这些发现突出了与之相关的风险仅依靠LLM来编码援助，强调开发人员对安全最佳实践保持警惕。研究人员建议进行潜在的改进，例如提高模型培训，以提高安全意识并将LLM与外部漏洞检测工具相结合以减轻监督。  您可以在此处捕获完整的故障：此处 您可以在这里捕获完整的原始研究论文：原始纸   &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1IW6610/do_llms_consider_security_an_empirical_empirical_study_on/&gt; [link]   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iw6610/do_llms_consider_security_an_empirical_study_on/</guid>
      <pubDate>Sun, 23 Feb 2025 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>谁拥有最大的AI斜坡？我刚刚达到1pb。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivy57v/who_has_the_biggest_pile_of_ai_slop_i_just_hit_1pb/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我是斜坡人吗？那个带有所有斜率的家伙？ 我正在创建像斜坡的巨型图书馆一样，所以我们都可以看一下斜坡，嗯，对此做事。因此，就像A&#39;slop Garden一样。 有人比我有更多的斜率吗？我希望能够声称我拥有宇宙中最大的AI斜坡。我还在吗？ 编辑：信不信由与否。提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivy57v/who_has_has_the_biggest_pile_pile_slop_ai_slop_i_i_just_hit_hit_hit_hit_1pb/  &lt;a href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivy57v/who_has_has_the_biggest_pile_pile_of_ai_slop_i_slop_i_just_hit_hit_1pb/]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivy57v/who_has_the_biggest_pile_of_ai_slop_i_just_hit_1pb/</guid>
      <pubDate>Sun, 23 Feb 2025 01:05:09 GMT</pubDate>
    </item>
    <item>
      <title>关于LLM的残酷真相</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  我已经使用LLMS了一段时间了，并且尝试了所有主要模型，我很好奇 - 他们如何改变您的生活？无论是刮胡子30分钟，还是只是让您感到压力/富有成效，我都对自己的经历感到好奇。让我们对此进行真实的态度。我注意到那里有很多炒作，并受到了很多批评。因此，忘记所有的AGI炒作或LLM是荣耀的摘要。让我们走到底部。  您的个人经历是什么样的？您在定量或定性上经历了什么切实的结果？   LLM帮助您的最令人惊讶的方法是什么？  LLM如何改变您的日常工作或心态？  我将其发布在所有相关的子列表上。我将尽可能清楚地更新结果。  编辑：摘要到发布后5小时。  那些在LLM中看到价值的人：5条评论（占8个评论的62.5％）。这些用户报告了有形的好处，例如节省时间，生产力提高，创造力的提高，减轻压力和例行变化，即使某些响应较少详细。 那些在LLMS中没有看到价值的人：3条评论（37.5）（37.5（37.5）（37.5总计8条评论的％）。这些用户要么缺乏个人经验，要么表达怀疑或恐惧，要么没有提供实质性的好处，其中一个是垃圾邮件。  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/briskprogress   href =“ https://www.reddit.com/r/artcoverinteligence/comments/1ivvkc0/the_brutal_truth_about_llms/”&gt; [link]   [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/</guid>
      <pubDate>Sat, 22 Feb 2025 22:59:27 GMT</pubDate>
    </item>
    <item>
      <title>在人工智能时代学习</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtefm/learning_in_the_ai_era/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  在人工智能时代的记忆是否过时？学校是否应该废除基于事实的学习并纯粹关注批判性思维？  &lt;！ -  sc_on-&gt;＆＃32;提交由＆＃32; /u/u/psych4you     [link]   ＆＃32;   [注释]   ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ivtefm/learning_in_the_ai_era/</guid>
      <pubDate>Sat, 22 Feb 2025 21:20:15 GMT</pubDate>
    </item>
    <item>
      <title>每月“有...是否有...”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[&lt;！ -  sc_off-&gt;  如果您有要使用AI的用例，但不知道要使用哪种工具，那么您可以在这里询问社区可以提供帮助，在这篇文章之外，这些问题将被删除。 对于每个人回答：没有自我促销，没有参考或跟踪链接。  &lt;！ -  sc_on-- - &gt;＆＃32;提交由＆＃32;态href =“ https://www.reddit.com/r/artcoverinteligence/comments/1hr4p1x/monthly_is_there_there_a_tool_tool_for_for_post/”&gt; [link]       [注释]  ]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>