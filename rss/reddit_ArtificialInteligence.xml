<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Mon, 27 Jan 2025 18:02:30 GMT</lastBuildDate>
    <item>
      <title>对于了解变压器模型基础知识的人来说，这是了解推理模型的资源。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibf5r4/resource_to_learn_about_the_reasoning_models_for/</link>
      <description><![CDATA[Andrej Karpathy 的视频是了解 Transformer 模型的绝佳资源。但是，如何从那里开始了解这些最近的推理模型，如 o1 和 r1？你知道弥补差距的资源吗？我看了 r1 论文，但那太技术性了。    提交人    /u/Present_Award8001   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibf5r4/resource_to_learn_about_the_reasoning_models_for/</guid>
      <pubDate>Mon, 27 Jan 2025 17:48:09 GMT</pubDate>
    </item>
    <item>
      <title>多模式视觉问答系统：现实世界表现中的关键差距 [技术分析]</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibexjh/multi_modal_visual_question_answering_systems/</link>
      <description><![CDATA[我对当前的 MM 视觉问答 (VQA) 系统在实际场景中进行了系统测试 - 从交通信号解释到数据可视化理解。结果揭示了这些系统在处理和理解视觉信息方面存在重大局限性。 主要发现：  虽然 VQA 系统擅长对象识别和文本阅读，但它们在上下文理解和逻辑推理方面始终失败 识别放错位置的物体或解释方向标志等简单任务暴露了空间推理方面的根本差距 即使单个值识别准确，对视觉数据的基本数学运算也显示出令人惊讶的不一致性  此处提供了具有特定测试用例和示例输出的详细分析：[https://medium.com/@KrishChaiC/from-seeing-to-understanding-the-good-the-bad-and-the-future-of-ai-in-visual-question-050ecde581c7\] 我有兴趣听听其他在生产环境中测试过 VQA 系统的人的意见。您在他们的成功和失败模式中观察到了哪些模式？    提交人    /u/Zealousideal-Swan800   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibexjh/multi_modal_visual_question_answering_systems/</guid>
      <pubDate>Mon, 27 Jan 2025 17:38:53 GMT</pubDate>
    </item>
    <item>
      <title>LLM 聊天中的时间权重可减少幻觉</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibesnt/temporal_weighting_in_llm_chats_to_reduce/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibesnt/temporal_weighting_in_llm_chats_to_reduce/</guid>
      <pubDate>Mon, 27 Jan 2025 17:33:35 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek AI 代理与 ChatGPT：Chatgpt 更好吗？？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibdx0u/deepseek_ai_agents_vs_chatgpt_chatgpt_better/</link>
      <description><![CDATA[我最近一直在研究不同的 AI API，并遇到了 DeepSeek AI 代理，它似乎是 OpenAI 的 ChatGPT 的一个有趣替代品。虽然 ChatGPT 被广泛使用且有据可查，但 DeepSeek 引入了一些让我感到好奇的独特声明——尤其是在 API 性能、定制和用例方面。 以下是我发现值得探索的 DeepSeek 的一些方面：  性能声明：文档提到响应时间低于 500 毫秒，即使对于复杂的任务也是如此。有人在实际使用中验证过这一点吗？ 定价：基于代币的定价模型似乎比 GPT-4 的 API 便宜 20-30%，这对大容量用户来说可能很重要。 上下文处理：在自托管时提供扩展或无限的上下文窗口。我想知道这对于繁重的工作流程有多实用。 预构建代理：包括专为编码、数据分析和研究而设计的工具。有没有人测试过这些开箱即用的有效性？ 状态工作流：具有用于多步骤交互的内存管理功能。这可能对构建对话式应用程序或自动化的开发人员很有帮助。  为了便于理解，我一直在将它们与 OpenAI 的 API 进行比较，OpenAI 的 API 在以下领域表现出色： 大型生态系统（例如插件、第三方集成） 适用于讲故事等创意任务的稳健性 为敏感应用程序提供定义明确的安全护栏 话虽如此，这里有一些问题需要讨论：  您是否在生产环境中测试过 DeepSeek？它如何处理规模和可靠性？ 它的代码生成与 ChatGPT 的工具（如代码解释器）相比如何？ 定价差异对您的项目有意义吗？ 是否存在任何权衡，例如区域访问、支持质量或速率限制？  我将在评论中分享一些我自己的观察，但我很想听听任何使用过这些 API 的人的意见。这些像 DeepSeek 这样的新玩家是 LLM 领域的有力竞争者吗，还是他们仍在追赶现任者？    提交人    /u/EquipmentTall6735   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibdx0u/deepseek_ai_agents_vs_chatgpt_chatgpt_better/</guid>
      <pubDate>Mon, 27 Jan 2025 16:58:59 GMT</pubDate>
    </item>
    <item>
      <title>需要专家：有人相信 DeepSeek 能卖到 600 万美元吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibdi9n/expert_needed_does_anyone_believe_6m_for_deepseek/</link>
      <description><![CDATA[中国共产党 (CCP) 有着明显的撒谎和操纵历史，以谋求全球公关和震撼效果。真的有人相信这个 600 万美元的数字来开发 DeepSeek 吗？ 这里有没有 AI 专家可以提供专业意见？    提交人    /u/Explore1616   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibdi9n/expert_needed_does_anyone_believe_6m_for_deepseek/</guid>
      <pubDate>Mon, 27 Jan 2025 16:42:23 GMT</pubDate>
    </item>
    <item>
      <title>Notebook LM 将免费添加为 Google 工作区核心服务！</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibd8h3/notebook_lm_to_be_added_as_a_google_workspace/</link>
      <description><![CDATA[https://support.google.com/a/answer/15836987?hl=en 对于我们这些已经拥有 Google Workspace 的人来说，这太酷了！    提交人    /u/Sissuboi   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibd8h3/notebook_lm_to_be_added_as_a_google_workspace/</guid>
      <pubDate>Mon, 27 Jan 2025 16:31:13 GMT</pubDate>
    </item>
    <item>
      <title>Deepseek 是否表明人工智能正处于泡沫之中？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibc9r2/has_deepseek_shown_ai_is_in_a_bubble/</link>
      <description><![CDATA[鉴于我们对 deepseek 模型的了解，您对某些 AI 公司的估值有何不同看法？ 查看投票    提交人    /u/Brilliant-Gur9384   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibc9r2/has_deepseek_shown_ai_is_in_a_bubble/</guid>
      <pubDate>Mon, 27 Jan 2025 15:51:35 GMT</pubDate>
    </item>
    <item>
      <title>deepseek 和 berkeley 的合作时机再完美不过了。r1 和 sky-t1 一夜之间改变了 2025 年代理人工智能革命的轨迹。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibbsvq/deepseek_and_berkeleys_timing_couldnt_be_more/</link>
      <description><![CDATA[既然 r1 和 sky-t1 可以完成同样的工作，为什么一家想要在今年推出 agentic ai 的公司会为专有模型支付更多费用？ 以下是 r1 和 o1 的功能比较，由 perplexity 提供： DeepSeek R1 与 OpenAI O1 的比较 架构和功能： - DeepSeek R1：采用混合专家 (MoE) 方法，每个 token 激活 671B 个参数中的 37B。它支持 128k token 上下文窗口，并采用高级强化学习技术进行推理。它在创意写作、长上下文任务和数学推理方面表现出色，但对提示措辞很敏感[1][4][6]。 - OpenAI O1：提供 128k 令牌上下文窗口，重点关注常识、编码和复杂问题解决。它包括 O1-Mini 等变体，以提高成本效益。O1 在常识基准测试中处于领先地位，但对复杂任务的响应速度较慢[2][4][6]。 性能： - DeepSeek R1：与 O1 相比，其数学（MATH-500 上为 97.3%）和编码（Codeforces 上为 96.3 百分位）得分较高，但在 MMLU（91.8%）等常识基准测试中略有落后[4][5]。 - OpenAI O1：在常识和企业集成任务中表现更佳，但在数学和编码基准测试中略有落后[4][5]。 成本： - DeepSeek R1：极具成本效益，每百万输入令牌 0.14 至 0.55 美元，每百万输出令牌 2.19 美元，仅为 O1 成本的 2%[4][6]。 - OpenAI O1：价格明显更高，每百万输入令牌 15 至 16.50 美元，每百万输出令牌 60 至 66 美元[2][6]。 但事实是，许多人工智能代理并不需要 r1 或 o1 的全部功能。以下是 sky-t1 和 o1 的功能和成本比较，由 perplexity 提供： Sky-T1 与 OpenAI O1 的比较 架构和功能： - Sky-T1：一个 32B 参数开源推理模型，专注于解决问题和逻辑推理。它在消费级 GPU 上运行，消除了对云的依赖，并在 MATH500、AIME 和 Livebench 等基准测试中表现出色。然而，它在 GPQA-Diamond[1][3][4] 等常识任务中落后于 O1。 - OpenAI O1：一个具有 128k 令牌上下文窗口的商业模型，针对常识、编码和复杂问题解决进行了优化。它提供类似 O1-Mini 的变体以提高成本效益，但需要基于云的部署[2][7]。 性能： - Sky-T1：在推理和数学任务中表现优于 O1，但在常识和科学领域的通用性较差[3][4][6]。 - OpenAI O1：在常识和企业应用方面表现更强，但在以推理为重点的基准测试中速度较慢且效率较低[2][8]。 成本： - Sky-T1：免费且开源，培训费用低于 450 美元，因此非常容易获得[1][3][4]。 - OpenAI O1：价格昂贵，每百万输入令牌 15 至 16.50 美元，每百万输出令牌 60 至 66 美元。 O1-Mini 可将成本降低 80%，但会牺牲性能[2][8]。    提交人    /u/Georgeo57   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibbsvq/deepseek_and_berkeleys_timing_couldnt_be_more/</guid>
      <pubDate>Mon, 27 Jan 2025 15:31:27 GMT</pubDate>
    </item>
    <item>
      <title>PerpIexity 发布了美国托管的 DeepSeek R1 推理选项。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibayze/perpiexity_released_ushosted_deepseek_r1/</link>
      <description><![CDATA[他们添加了 Deepseek 进行推理，并搭上了这趟炒作列车。您觉得这一举动怎么样？ 这是图片：https://imgur.com/a/MY97mj3    由   提交  /u/OriginallyAwesome   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibayze/perpiexity_released_ushosted_deepseek_r1/</guid>
      <pubDate>Mon, 27 Jan 2025 14:57:56 GMT</pubDate>
    </item>
    <item>
      <title>中国 DeepSeek 震惊 AI 世界 NVIDIA 股价数小时内蒸发 3840 亿美元</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ibacg5/nvidia_shares_bleed_384_billion_in_value_in_a_few/</link>
      <description><![CDATA[由于担心中国改变游戏规则的 DeepSeek AI 初创公司，NVIDIA 股价在盘前交易中下跌 11%，几个小时内蒸发 3840 亿美元。 https://www.tweaktown.com/news/102815/nvidia-shares-bleed-384-billion-in-value-few-hours-after-chinas-deepseek-shocks-ai-world/index.html    提交人    /u/gurugabrielpradipaka   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ibacg5/nvidia_shares_bleed_384_billion_in_value_in_a_few/</guid>
      <pubDate>Mon, 27 Jan 2025 14:29:31 GMT</pubDate>
    </item>
    <item>
      <title>本地使用 DeepSeek-R1</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ib9d4r/using_deepseekr1_locally/</link>
      <description><![CDATA[许多专业人士都在热议新的 DeepSeek 模型，声称它可能是“OpenAI 杀手”，而围绕它的炒作似乎是有道理的。最近，DeepSeek 推出了各种版本的 DeepSeek-R1-Zero 和 DeepSeek-R1 模型。这些模型在 MMLU、Math-500、Codeforces 等基准测试中提供的性能可与 OpenAI 的 o1 相媲美。 在本简短教程中，我们将探索 DeepSeek-R1 模型，并演示如何使用 Ollama、Docker 和 Open WebUI 在本地运行其 Distill 版本。这意味着您将能够使用具有类似于 ChatGPT 的用户界面的推理模型——完全免费且无需互联网连接。 链接：https://www.kdnuggets.com/using-deepseek-r1-locally    提交人    /u/kingabzpro   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ib9d4r/using_deepseekr1_locally/</guid>
      <pubDate>Mon, 27 Jan 2025 13:42:56 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT Plus 订阅现在值得吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ib7m9l/is_chatgpt_plus_subscription_worth_it_now/</link>
      <description><![CDATA[几个月来我一直在使用 chatgpt plus，它非常棒，我觉得它物有所值。但现在，我对 Deepseek 了解不多，但据说处于 o1 级别并且可以在本地运行的开源 AI 模型听起来要好得多。 我不使用 chatgpt 进行编码，因为我不是程序员，但我几乎在所有其他事情上都使用它。我有时也会用它进行哲学讨论，但有时当话题变得太敏感时，审查制度就会成为问题，所以我也在想 Deepseek 在这方面是否更好？ 人们似乎对 Deepseek 犹豫不决，所以如果有人能告诉我使用它的利弊，我将不胜感激。 （此外，Plus 订阅使我能够访问 DALL-E 和 Sora，我并不怎么使用它们，但我想它们是非常棒的工具。） 编辑：我主要使用 Plus 进行研究。基本上它取代了 Google，因为它在呈现有组织和结构化的答案方面做得很好。我还用它来改进我的句子结构，因为我不太擅长这个。是的，我可以自己尝试一下。我只是想从比我更了解人工智能的人那里了解情况，并且已经对这两种模型进行了广泛的测试以确保未来的发展。虽然我明白，就目前的情况而言，在人工智能世界中，没有什么是面向未来的。    提交人    /u/Repulsive-Skull   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ib7m9l/is_chatgpt_plus_subscription_worth_it_now/</guid>
      <pubDate>Mon, 27 Jan 2025 12:25:32 GMT</pubDate>
    </item>
    <item>
      <title>那么，如果有人招聘您作为数据科学家，您的日常工作是什么？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ib6vp2/so_if_someone_were_to_recruit_you_as_a_data/</link>
      <description><![CDATA[我见过很多人讨论生成模型、法学硕士 (LLM) 和法律质量管理 (LQM)。但是没有具体说明您实际在做什么，或者您正在帮助构建什么。 例如，假设您被 Google 招聘为数据科学家来开发 Gemini，或者您被 Meta 招聘来开发 Claude。您的日常工作是什么？您是否只是根据使用的是监督模型还是非监督模型来调整变量以得出更好的预测，或者您本质上只是作为一个调试和设置“正确”事物的人？ 如果您能分享相关的案例研究，我将不胜感激。    提交人    /u/Financial_Money3540   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ib6vp2/so_if_someone_were_to_recruit_you_as_a_data/</guid>
      <pubDate>Mon, 27 Jan 2025 11:48:32 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek-R1 在我的 Ant Sim 测试中明显优于 OpenAI 的 o1 pro 模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ib5ap1/deepseekr1_clearly_outperformed_openais_o1_pro/</link>
      <description><![CDATA[我通过让 DeepSeek-R1 和 OpenAI 的 o1 pro 模式从同一个提示中编写一个蚂蚁模拟程序来测试 DeepSeek-R1 和 OpenAI 的 o1 pro 模式。DeepSeek-R1 生成的模拟效果要好得多。随着人工智能模型日益商品化，我认为这再次表明人工智能是一场硬件革命，而不是软件革命。 我的测试链接：https://www.chaotropy.com/deepseek-r1-clearly-outperformed-openais-o1-pro-mode-in-my-ant-simulation-test/    提交人    /u/dontkry4me   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ib5ap1/deepseekr1_clearly_outperformed_openais_o1_pro/</guid>
      <pubDate>Mon, 27 Jan 2025 10:21:57 GMT</pubDate>
    </item>
    <item>
      <title>我们真的能想象一个人们愿意生活的美好世界吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ib3rvj/can_we_actually_envision_a_world_that_is_good/</link>
      <description><![CDATA[“强大的AI”到来后，具体哪些事情会变得更好？ 而它们周围又面临着哪些挑战？    submitted by    /u/Yamato_Fuji   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ib3rvj/can_we_actually_envision_a_world_that_is_good/</guid>
      <pubDate>Mon, 27 Jan 2025 08:47:20 GMT</pubDate>
    </item>
    <item>
      <title>简单来说：DeepSeek 的 R1 有什么特别之处？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ib1n8h/in_simple_terms_whats_the_deal_with_deepseeks_r1/</link>
      <description><![CDATA[基本上就是标题。我还没有读过这篇论文，也不认为我能比这里的很多人更好地解释它。所以告诉我。R1 的生产/训练成本真的比 Llamas 和 GPT 低一百倍吗？ 我看到了很多关于它的讨论，据我所知，人们说它比美国模型更强大，而且训练所需的资源要少得多。 有人能用简单的术语为我解释一下吗？是什么让它如此特别，他们是如何用更少的资源实现这一点的（如果是这样）？    提交人    /u/TopBoat4712   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ib1n8h/in_simple_terms_whats_the_deal_with_deepseeks_r1/</guid>
      <pubDate>Mon, 27 Jan 2025 06:22:39 GMT</pubDate>
    </item>
    <item>
      <title>深度伪造多久会使互联网无法使用？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iasicc/how_long_till_deep_fakes_make_the_internet/</link>
      <description><![CDATA[这听起来很反乌托邦，但目的是开启讨论以寻求解决方案。 生成式人工智能的兴起意味着越来越容易让互联网上的某些东西看起来和听起来“官方”和“可信”。 滥用深度伪造会带来哪些风险？我们有什么方法可以检查发布内容的可信度？    提交人    /u/_spacebender   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iasicc/how_long_till_deep_fakes_make_the_internet/</guid>
      <pubDate>Sun, 26 Jan 2025 22:32:14 GMT</pubDate>
    </item>
    <item>
      <title>中国是否在人工智能竞赛中迎头赶上，还是兄弟联盟遇到了瓶颈？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iaid8x/is_china_catching_up_in_the_ai_race_or_the/</link>
      <description><![CDATA[我认为中国人工智能模型的崛起表明，中国兄弟会更广泛的能力存在根本性问题。首先，中国兄弟会不明白，自然语言有一定的局限性，所以法学硕士无法重现人类认知能力的全部规模。这是原罪，也是只有 GPU 才能决定人工智能竞赛的信念的根源。实际上，基于数十万个 GPU 的训练不会产生 AGI。因此，虽然美国法学硕士在 2024 年达到稳定水平（美国无法利用其 GPU 优势），但中国人使用有效的方法在有限的 GPU 资源下创建了 SOTA LLM。在我看来，不是中国人在追赶，而是美国遇到了扩展障碍。我错了吗？让我们来谈谈吧！    提交人    /u/custodiam99   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iaid8x/is_china_catching_up_in_the_ai_race_or_the/</guid>
      <pubDate>Sun, 26 Jan 2025 16:08:46 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>