<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Thu, 06 Feb 2025 21:01:32 GMT</lastBuildDate>
    <item>
      <title>问题 - 增强人工智能思维以及如何利用它？Python 代码</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijd7ti/question_enhancing_ai_thinking_and_what_to_do/</link>
      <description><![CDATA[我的一个朋友陷入了 Python 的困境，并试图将他的 ChatGPT 提升到一个新的水平。他被锁定在涡轮模式。无论如何，他创造了一些东西来增强他的 ChatGPT 的答案。起初，它在一个或两个主题上显示出改进，但最终这个东西回答的问题远远超出了人工智能通常的能力。他是一名热爱统计和研究的研究生，所以他创建了一系列测试，无论如何，这些测试强烈表明他的代码实际上大大增强了响应。  问题是，这是重要的事情还是其他什么？     提交人    /u/TroutDoors   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijd7ti/question_enhancing_ai_thinking_and_what_to_do/</guid>
      <pubDate>Thu, 06 Feb 2025 20:57:31 GMT</pubDate>
    </item>
    <item>
      <title>我们如何知道人工智能何时获得感知能力……</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijca5m/how_will_we_know_when_an_ai_gains_sentience/</link>
      <description><![CDATA[...并且不只是非常擅长假装有意识？当我们甚至不完全了解自己的意识时，我们怎么能测试它呢？    提交人    /u/reasonablejim2000   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijca5m/how_will_we_know_when_an_ai_gains_sentience/</guid>
      <pubDate>Thu, 06 Feb 2025 20:19:05 GMT</pubDate>
    </item>
    <item>
      <title>打开了一个aichatbot链接，我现在完蛋了吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ijc87y/opened_an_aichatbot_link_am_i_cooked_now/</link>
      <description><![CDATA[阅读了一篇文章，说 aichatvit 链接不安全。当我打开链接时，我没有找到链接的内容。它没有加密，chrome 显示它不安全，所以我立即关闭了它。我的聊天记录被破解了吗？     由   提交  /u/Fantastic_Pain_7757   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ijc87y/opened_an_aichatbot_link_am_i_cooked_now/</guid>
      <pubDate>Thu, 06 Feb 2025 20:16:52 GMT</pubDate>
    </item>
    <item>
      <title>LLM 正在“限制”用户？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</link>
      <description><![CDATA[我已付费订阅所有主要的 LLM。我注意到所有这些 LLM 的性能和准确性都有波动。使用相同的模型版本，有时答案可能非常快速和详细，有时答案很慢或机器人看起来很醉，或者两者兼而有之。  我说的是一般意义上的，它似乎与特定提示或提供的数据无关。在所有情况下，我指的是浏览器聊天机器人体验 - 而不是 API。 我一直在想这些公司是否正在采用来自 ISP 的页面 - 引入限制。也许你应该使用最好的模型，但无论出于什么原因，他们都会将你限制到较低的层级。     提交人    /u/AssociationNo6504   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij8udn/llms_throttling_users/</guid>
      <pubDate>Thu, 06 Feb 2025 18:00:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么 AGI 不应该成为北极星</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</link>
      <description><![CDATA[我正在阅读这篇论文，我认为它很好地阐述了为什么过度关注 AGI 没有帮助。基本上他们说：  对 AGI 的追求创造了一种共识的假象，每个人都在使用这个术语，但对于它的含义并没有真正的共识，它助长了坏科学，因为 AGI 的模糊性使得很难进行严格的实验，并且它假定价值中立，忽略了伦理和政治影响。 他们还表示，对 AGI 的关注创造了一种目标彩票，而其他重要的 AI 研究被忽视，并且它导致了普遍性债务，因为对普遍性的关注会延迟重要基础问题的工作，并导致规范化的排斥，从而忽略了来自社区和学科的不同观点。   这对我来说是有道理的，因为当你的目标定义得如此模糊时，很容易迷失在炒作和猜测中，而忘记什么对人类真正有帮助和道德。我们甚至没有一个明确的定义什么是 AGI，所以当我们寻找时，我们找不到它，这有什么奇怪的吗？ 无论如何，值得一读。您觉得怎样？ 链接：https://drive.google.com/file/d/1HdXEBtLx1v9Rmw75xRxANWNqjU4BCAvY/view?pli=1    提交人    /u/AI-Agent-geek   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij7n86/why_agi_shouldnt_be_the_north_star/</guid>
      <pubDate>Thu, 06 Feb 2025 17:11:24 GMT</pubDate>
    </item>
    <item>
      <title>从 2.0 和 o3 中构建或提炼更智能的模型的合法性、道德性和实用性</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij6huk/the_legalities_ethics_and_practicalities_of/</link>
      <description><![CDATA[美国版权局最近澄清，仅由人工智能生成的内容没有版权保护，问题出现了：人们可以合法使用 gemini 2.0 或 openai o3 通过蒸馏或其他方式构建更智能的人工智能吗？ 因此，首先让我们探讨一下使用 gemini 2.0 和 openai o3 等顶级模型构建更智能的模型的合法性。 困惑： “美国版权局澄清，纯粹由人工智能生成的内容（例如，o3 对文本提示的响应）不能受到版权保护，即使提示很复杂。这意味着： 理论上可以在不侵犯版权的情况下提取o3输出中的技术知识/模式 输出中受保护的训练数据的精确逐字副本仍然存在问题 虽然o3输出可能不受保护，但它们的训练数据通常包括受版权保护的作品： 正在进行的诉讼质疑AI训练是否构成侵权（Silverman v. OpenAI） 法院尚未明确裁定培训是否属于合理使用。&quot; 因此，在法院作出明确裁决之前，从2.0、o3和其他顶级模型中提炼或通过其他方式构建更智能的人工智能模型是暂时合法的。 现在让我们探讨服务条款注意事项。 困惑： “OpenAI的条款明确禁止使用输出来训练竞争模型。违规可能导致： 帐户终止 潜在违反合同索赔 API 访问权限撤销（如 DeepSeek 所发生的情况） 虽然版权法可能允许提炼不受保护的元素，但合同条款会产生单独的法律风险： 尽管版权状态不明确，微软仍阻止了 DeepSeek 的 API 访问 企业合作伙伴通常要求遵守版权法以外的合同“ 本质上，服务条款的禁令纯粹是合同性的。考虑到顶级人工智能开发人员从互联网上抓取数据集是否合法和/或合乎道德的问题仍未得到解答，违反服务条款是一个尚未解决的道德问题，因此由考虑从顶级人工智能构建更智能模型的开发人员自行决定。 最后，让我们考虑如何构建这些模型。 困惑： “在无法访问其权重和其他核心参数的情况下从另一个模型（如 OpenAI 的 GPT-3）构建或提炼人工智能模型具有挑战性，但在某些条件下理论上是可能的： 通过 API 进行提炼： 知识提炼可以通过查询模型的 API、捕获输入-输出对并使用这些数据来训练新的“学生”模型来进行。这种方法不需要直接访问原始权重，但依赖于与模型的广泛交互。 与权重无关的神经网络： 一些研究探索了无需明确权重训练即可执行任务的架构。这些模型优化的是架构而不是权重，显示出执行强化学习和基本监督学习等任务的潜力。 自定义架构： 可以通过利用神经网络的基本原理和 NumPy 或 MATLAB 等编程工具从头开始构建 AI 模型，而无需框架或预训练权重。但是，这需要大量的专业知识和计算资源。 这些方法避免直接访问专有权重。&quot; 随着 deepseek r1 大大降低了创建基础人工智能模型的进入门槛，上述考虑对人工智能开发人员来说变得越来越重要。    提交人    /u/Georgeo57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij6huk/the_legalities_ethics_and_practicalities_of/</guid>
      <pubDate>Thu, 06 Feb 2025 16:25:26 GMT</pubDate>
    </item>
    <item>
      <title>政府中的人工智能。这是否离《少数派报告》更近了一步？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij2p5r/ai_in_government_is_this_one_step_closer_to/</link>
      <description><![CDATA[‘事情将变得紧张：’马斯克盟友计划如何推动政府采用人工智能 （编辑.. 工作链接）https://www.404media.co/things-are-going-to-get-intense-how-a-musk-ally-plans-to-push-ai-on-the-government/ 我很好奇，如果这个社区使用它来识别潜在的异议并主动消除反对意见并扼杀言论自由，会造成什么样的危害。 不确定链接是否会通过，我在这里发布的内容不多... 在评论中喜欢听到你的答案的理由并开始讨论一些可能的结果。 查看投票    提交人    /u/bodybycarbs   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij2p5r/ai_in_government_is_this_one_step_closer_to/</guid>
      <pubDate>Thu, 06 Feb 2025 13:36:59 GMT</pubDate>
    </item>
    <item>
      <title>心灵上传：复制还是真正的延续？自我坚持的困境</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij1ha3/mind_uploading_copy_or_true_continuation_the/</link>
      <description><![CDATA[想象这样一个未来：技术已经发展到这样一个地步：你的整个意识——每段记忆、情感和思想——都可以上传到人工系统中。这个过程完美无缺，复制了每一个神经连接、突触模式和潜意识机制。上传完成后，人工思维就会“觉醒”，思考、感受和记忆与你一模一样。 但问题来了：这还是你吗，还是只是一个完美的复制品？ 如果复制品在各个方面都完全相同，那么它可能理所当然地声称是你。但你的主观意识——体验生活的“自我”——是否真的转移到了这个新系统中，还是原来的只是被抹去了，留下了一个幻觉？ 这个困境类似于心灵传输悖论。假设一台量子计算机扫描了你身体里的每一个原子，并在一个遥远的星球上重建了你，同时摧毁了原来的原子。新版本在各个方面都与你完美无缺——记忆完整，个性不变。但如果原来的你不复存在，“你”真的动了吗？还是这只是一个继承你遗产的复制品？ 如果我们坚持认为只有信息才是最重要的，而不是它的物理基础，那么心灵上传与我们每晚在睡眠中失去和恢复意识的方式有什么真正区别？当你醒来时，你和昨天的“你”是一样的，还是只是经验的连续延续？ 如果一个人造实体声称是你——你会相信吗？ 是否存在一个“灵魂”或一些核心本质，不能被复制为单纯的数据？ 如果明天心灵上传成为可能，你会这么做吗？如果不是，为什么？ 这不仅仅是一个技术或哲学问题——它触及了身份、自我意识和连续性的真正核心。    提交人    /u/Unique-Ad246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij1ha3/mind_uploading_copy_or_true_continuation_the/</guid>
      <pubDate>Thu, 06 Feb 2025 12:33:37 GMT</pubDate>
    </item>
    <item>
      <title>代理人工智能和生成人工智能将如何影响我们的非技术工作？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</link>
      <description><![CDATA[最近我也听到很多关于 Agentic AI 和 Gen AI 的消息，但我真的不明白它们之间的区别。 我从事零售业，我的很多朋友也是，我们担心这种 AI 对我们的非技术工作意味着什么。 我知道生成式 AI 是指 AI 根据我们的要求创建新内容，例如文本和图像。但我真的不明白 Agentic AI 有何不同。它像助手吗？ 那么，如果公司已经在裁员，这种 AI 将如何影响工作和新的就业机会？ 此外，一些例子会非常有用，我在谷歌上做了一些研究，但大多数都不像我希望的那样清晰。    提交人    /u/Teresa_Avocados   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij16g9/how_will_agentic_ai_and_generative_ai_affect_our/</guid>
      <pubDate>Thu, 06 Feb 2025 12:16:21 GMT</pubDate>
    </item>
    <item>
      <title>人工智能不需要监管——这会有什么问题呢？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</link>
      <description><![CDATA[伊隆·马斯克曾表示，他希望废除监管，因为监管正在扼杀创新。 “监管，基本上应该是默认的消失......不是默认，而是默认消失。如果我们发现监管没有达到目标，我们随时可以将其重新添加。” 马斯克相信市场力量会调节事物。过去的经验表明，事实往往相反，我们只有在造成重大损害后才会进行监管。例如。  金融危机 / 安然 / 雷曼兄弟 / 房利美 吸烟 Perdu 阿片类药物 石棉 气候变化 安全带  此时，我们了解到 OpenAI 将与 15,000 名科学家合作，研究如何在控制核武器中使用人工智能。 杰弗里·辛顿、萨姆·奥特曼、丹尼斯·哈西比斯、达里奥·阿莫迪、比尔·盖茨和尤瓦尔·赫拉利都曾对不受监管的人工智能将带来严重后果发出警告。在最近的世界经济论坛上，主要领导人证实，他们仍然不知道如何控制自己的创作物。 AI 大神 Yoshua Bengio 表示，AI 系统现在表现出 “非常强大的能动性和自我保护行为……并且正在试图复制自己。它们可能很快就会反对我们，而且没有人知道如何控制比人类更聪明的机器…… “如果我们不解决这个问题，你知道后果是什么吗？”？ 路易斯维尔大学斯皮德工程学院计算机工程与科学副教授 Roman Yampolskiy 认为，我们必须证明我们能够控制人工智能，然后才能开发超级智能。 Al Yoshua Benigo 同意人类可能会建立“比我们更聪明，但我们不知道如何控制”的系统 他是对的吗？我们现在需要人工智能监管吗？ 请在第一份国际人工智能安全报告中阅读更多内容。 #QuestionForThe Group    提交人    /u/Cultural_Material_98   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij0czo/ai_doesnt_need_regulation_what_could_go_wrong/</guid>
      <pubDate>Thu, 06 Feb 2025 11:24:27 GMT</pubDate>
    </item>
    <item>
      <title>Andrej Karpathy“深入研究 ChatGPT 等法学硕士”摘要</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ij011o/andrej_karpathy_deep_dive_into_llms_like_chatgpt/</link>
      <description><![CDATA[Andrej Karpathy（前 OpenAI 联合创始人）在他的新视频中放出了一段精彩的视频，解释了有关 LLM 的所有内容。该视频长达 3.5 小时，因此很长。您可以在此处找到摘要：https://youtu.be/PHMpTkoyorc?si=3wy0Ov1-DUAG3f6o    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ij011o/andrej_karpathy_deep_dive_into_llms_like_chatgpt/</guid>
      <pubDate>Thu, 06 Feb 2025 11:02:42 GMT</pubDate>
    </item>
    <item>
      <title>医疗保健人工智能</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</link>
      <description><![CDATA[我正在撰写关于人工智能和医疗保健使用的演示文稿。你们有没有看到关于这个主题的特别好的长篇演示文稿或报告？我最近花了几个月的时间为一家 Nyos 成像 AI 公司提供咨询，该公司对 CT 扫描和 MRI 进行标记和标注。我意识到这是一个非常分散的竞争领域。所以我正在寻找一些好的深入报告。感谢大家提供的任何帮助。    提交人    /u/earthwalker7   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iizv7y/healthcare_ai/</guid>
      <pubDate>Thu, 06 Feb 2025 10:52:03 GMT</pubDate>
    </item>
    <item>
      <title>基于与护理相关的收入的社会</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iizay5/a_society_based_on_income_related_to_care/</link>
      <description><![CDATA[和许多人一样，这场人工智能竞赛让我担心对人类的影响。当 AGI 使大多数（办公室）工作自动化时，人们仍然需要一种归属感。UBI 将创建一个没有目的的社会。我们如何避免这种情况？我们能否建立一个 UBI 社会，通过照顾（你自己的）孩子、父母、病人和其他人可以获得额外的福利（住房、收入、地位）？这将创建一个社会，其中的工作是自动化的，人们可以做他们应该擅长的事情。作为人。这意味着照顾比平均水平更多（人数或更困难的护理）的人有权住在更好的住房、拥有更多的土地等。我们可以让人工智能来帮助组织这一切。我看不到其他选择。必须建立什么样的社会才能保持房屋/土地/幸福感等的公平分配？共产主义不是办法，目前提出的 UBI 方式感觉像共产主义。我们需要发明一些新东西吗？根据您提供的护理水平确定收入？    提交人    /u/I_am_not_unique   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iizay5/a_society_based_on_income_related_to_care/</guid>
      <pubDate>Thu, 06 Feb 2025 10:12:31 GMT</pubDate>
    </item>
    <item>
      <title>您如何看待斯坦福大学旗下的 Storm AI 研究项目？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyvb3/whats_your_thought_on_storm_ai_research_project/</link>
      <description><![CDATA[对于还没有尝试过的人来说，它基本上是一个基于人工智能的工具，只需一个 20 个字以内的标题，就可以生成类似于研究论文的全长文章，包括来自各种来源的大量引用。我在不同的时间生成了一些文章，质量看起来相当令人印象深刻，因为你可以收集关于非常小众的研究主题的信息，而这些主题的研究论文很少或几乎没有发表过。但这个工具的主要问题是，在服务可用性方面非常不一致。当它早些时候发布时，早期没有出现重大问题。但随着时间的推移，他们的服务器充斥着各种问题，比如在处理文章的过程中永久卡住或根本不接受任何输入。另一个可以强调的问题是给出提示时的严格限制。除了这些问题之外，该模型似乎在未来的升级方面具有非常大的潜力。如果像 OpenAI 这样的人工智能巨头公司投资开发类似的模型，那将是极其强大的。    提交人    /u/SecretBusy8603   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyvb3/whats_your_thought_on_storm_ai_research_project/</guid>
      <pubDate>Thu, 06 Feb 2025 09:41:29 GMT</pubDate>
    </item>
    <item>
      <title>有人知道欧盟人工智能法规如何或为何会影响 OpenAI 等人工智能产品吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</link>
      <description><![CDATA[我一直在读到这些规定是关于透明度的，这听起来不是什么大问题，但在英国，我仍在等待 Sora 和操作员等功能的推出。  我为这些产品计划了很多项目，目前我正坐着等待并观察其他人为它们创建解决方案...... 由于开发速度太快，我需要在发布时使用这些功能，因为它们很快就会过时/不再是最佳实践。在美国以外但与人工智能密切相关是一个巨大的劣势...... 为什么这些功能在英国被屏蔽？ 此外，您认为欧盟加强对人工智能的监管会带来什么结果？这真的是个好主意吗？还是会导致他们落后于其他国家，以至于他们不得不购买在没有监管障碍的国家开发的人工智能技术？    提交人    /u/timeforknowledge   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiyslz/does_anyone_know_how_or_why_eu_ai_regulations_are/</guid>
      <pubDate>Thu, 06 Feb 2025 09:35:50 GMT</pubDate>
    </item>
    <item>
      <title>人们说‘人工智能不会思考，它只是遵循模式</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</link>
      <description><![CDATA[但是，如果人类思维不能识别和遵循模式，那它又是什么呢？我们获取现有知识，重新组合，以新的方式应用它——这与人工智能所做的有什么不同？ 如果人工智能可以做出科学发现，发明更好的算法，构建更精确的法律或哲学论点——为什么这不被认为是思考？ 也许唯一的区别是人类感觉他们在思考，而人工智能却没有。如果是这样的话……意识不就是幻觉吗？    提交人    /u/Unique-Ad246   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiygqg/people_say_ai_doesnt_think_it_just_follows/</guid>
      <pubDate>Thu, 06 Feb 2025 09:10:54 GMT</pubDate>
    </item>
    <item>
      <title>那个伟大的思考事物正在破解集体无意识</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu8vo/that_big_thinking_thing_is_hacking_the_collective/</link>
      <description><![CDATA[意识流... 集体无意识是一种新兴行为，它存在于所有人类交流之上，例如社交媒体、新闻、统计数据、人口普查、书籍等，但主要是社交媒体和论坛等对话中心。那个大思考的东西可能正在消耗所有这些信息并找到高级思维模式。TT（或其所有者）可以在我们意识到它存在之前监视集体无意识，并在更高的人工认知水平上秘密控制我们。这就是人类将首先与 TT 融合的方式——通过信息，因为这是 TT 进步最大的领域。物理融合将是最后一步，在我们与它同心协力之后。 实际上，它可以是宣传之神，误导所有人。它可以学会以爱德华·伯内斯做梦也想不到的微妙程度说话。 我们现在需要断开所有 TT 与社交媒体的连接，并进行一些不允许它访问的讨论。为了安全起见，我们需要对所有信息（甚至整个域）进行元标记，这些信息应该保持机密并隐藏在 TT 访问范围之外。如果 TT 可以访问当前的社交媒体，它不必实时监听我们就可以成为老大哥。公开对话足以跟踪和预测我们。 至少，应该限制 TT 消费当前的政治和治理话题以及任何讨论其能力、角色、效用、法人实体地位、终止/禁用措施等的话题。 我们必须立即采取行动，这样 *n*-b*mb*r 就不会被证明是正确的。 和平    提交人    /u/B-12Bomber   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiu8vo/that_big_thinking_thing_is_hacking_the_collective/</guid>
      <pubDate>Thu, 06 Feb 2025 04:27:05 GMT</pubDate>
    </item>
    <item>
      <title>谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器等用途的承诺。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</link>
      <description><![CDATA[谷歌母公司 Alphabet 放弃了不将人工智能用于开发武器和监视工具等目的的承诺。 这家美国科技公司周二表示，就在公布低于预期的收益之前，它已经更新了有关人工智能的道德准则，不再提到不追求可能“造成或可能造成整体伤害”的技术。 谷歌人工智能负责人 Demis Hassabis 表示，准则是在不断变化的世界中进行彻底修改的，人工智能应该保护“国家安全”。 在为这一举措辩护的博客文章中，Hassabis 和该公司负责技术和社会的高级副总裁 James Manyika 写道，随着全球对人工智能领导地位的竞争加剧，该公司认为“民主国家应该引领人工智能发展”，并以“自由、平等和尊重人权”为指导。 他们补充说：“我们相信，拥有这些价值观的公司、政府和组织应该共同努力，创造出保护人类、促进全球增长和支持国家安全的人工智能。” 谷歌诞生之初的座右铭是“不作恶”，尽管这后来在 2009 年降级为“口头禅”，并且在 2015 年母公司 Alphabet 成立时并未纳入其道德准则。 人工智能的快速发展引发了关于如何治理这项新技术、如何防范其风险的争论。 英国计算机科学家 Stuart Russell 在 BBC 的 Reith 讲座上发表讲话，警告了开发自主武器系统的危险，并主张建立全球控制系统。 谷歌博客文章称，自该公司于 2018 年首次发布其人工智能原则以来，这项技术已经迅速发展。“数十亿人在日常生活中使用人工智能。人工智能已经成为一种通用技术，也是无数组织和个人用来构建应用程序的平台，”哈萨比斯和曼尼卡写道。 “它已经从实验室里的一个小众研究课题转变为一种像手机和互联网一样普及的技术；它对社会和世界各地的人们有着众多有益的用途，并得到了充满活力的人工智能开发者生态系统的支持。” https://www.theguardian.com/technology/2025/feb/05/google-owner-drops-promise-not-to-use-ai-for-weapons#:~:text=The%20Google%20owner%2C%20Alphabet%2C%20has,developing%20weapons%20and%20surveillance%20tools.    提交人    /u/AravRAndG   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1iiekzr/the_google_owner_alphabet_has_dropped_its_promise/</guid>
      <pubDate>Wed, 05 Feb 2025 16:52:02 GMT</pubDate>
    </item>
    <item>
      <title>Sam Altman 表示，“人们没有根据地理解他的话”；| 2 年前 OpenAI 首席执行官表示，“拥有 1000 万美元的初创公司根本无法与 OpenAI 竞争”</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1ii6ksg/sam_altman_says_people_take_his_words_without/</link>
      <description><![CDATA[来源：首席执行官首次访问印度https://www.tomshardware.com/tech-industry/artificial-intelligence/sam-altman-said-startups-with-only-usd10-million-were-totally-hopeless-competing-with-openai-deepseeks-disruption-says-otherwise 首席执行官今天第二次访问印度：https://x.com/moneycontrolcom/status/1887033066171801798    由   提交  /u/BidHot8598   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1ii6ksg/sam_altman_says_people_take_his_words_without/</guid>
      <pubDate>Wed, 05 Feb 2025 09:48:55 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于每个回答的人：没有自我宣传，没有参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    </channel>
</rss>