<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>人工智能网关</title>
    <link>https://www.reddit.com/r/ArtificialInteligence</link>
    <description>r/ArtificialIntelligence 的目标是为人工智能社区的方方面面提供一个门户，并促进有关我们所知的人工智能思想和概念的讨论。这些可能包括哲学和社会问题、艺术和设计、技术论文、机器学习、如何开发人工智能/机器学习项目、商业中的人工智能、人工智能如何影响我们的生活、未来可能的发展方向以及许多其他主题。欢迎。</description>
    <lastBuildDate>Fri, 10 Jan 2025 06:01:39 GMT</lastBuildDate>
    <item>
      <title>微软的 rStar-Math：7B LLM 与 OpenAI o1 在数学方面的表现相当</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxxjlu/microsofts_rstarmath_7b_llms_matches_openai_o1s/</link>
      <description><![CDATA[微软最近发表了“rStar-Math：小型 LLM 可以通过自我进化的深度思维掌握数学”，展示了一种名为 rStar-Math 的技术，该技术可以让小型 LLM 使用代码增强思维链掌握数学。论文摘要以及 rStar-Math 的工作原理：https://youtu.be/ENUHUpJt78M?si=JUzaqrkpwjexXLMh    提交人    /u/mehul_gupta1997   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxxjlu/microsofts_rstarmath_7b_llms_matches_openai_o1s/</guid>
      <pubDate>Fri, 10 Jan 2025 05:40:34 GMT</pubDate>
    </item>
    <item>
      <title>人工智能盈利能力的咆哮和投资。买什么股票？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxxa9k/ai_profitability_rant_and_investing_what_stocks/</link>
      <description><![CDATA[没有人赚钱。到目前为止，它几乎是一个非盈利部门。Open Ai 远未盈利，其他 3-4 家也是如此。Meta 正在亏损。埃隆·马斯克在他的“我也是”的事情上浪费钱。 知道 AWS 有多便宜，他们可能会赚一些钱，但数据中心的投资回报率就像 Azure 一样，是一个长期的游戏。 微软肯定没有盈利，因为他们必须为 OpenAi 数据中心基础设施支付巨额费用。 数据中心提供商可能会看到一些钱，但同样，这是一个长期的投资回报率，所以它还没有盈利。 对于 DELL 和 SMCI，我不确定。SMCI 充满了狗屁计划。戴尔利润很薄或没有利润。 所以这是一个疯狂的游戏，但现实是每个人都在赔钱，只有 NVIDIA 是盈利的。哈哈，你编不出这个狗屎。 我想到的唯一另一个是 ARM。还有什么？    提交人    /u/Motor_Card_8704   [link] [comments]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxxa9k/ai_profitability_rant_and_investing_what_stocks/</guid>
      <pubDate>Fri, 10 Jan 2025 05:24:06 GMT</pubDate>
    </item>
    <item>
      <title>谁真正利用人工智能赚大钱了？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxwpl3/who_is_actually_making_big_money_with_gen_ai/</link>
      <description><![CDATA[严肃的问题：除了 Nvidia / 芯片制造商之外，是否还有哪些事实驱动的数据表明，拥有可持续商业模式的公司是否利用人工智能获得巨额利润？    提交人    /u/No_Watercress_1146   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxwpl3/who_is_actually_making_big_money_with_gen_ai/</guid>
      <pubDate>Fri, 10 Jan 2025 04:49:58 GMT</pubDate>
    </item>
    <item>
      <title>在学习一门新语言方面，人工智能（ChatGPT、Gemini 等）表现如何？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxvbfe/how_good_is_ai_chatgpt_gemini_etc_when_it_comes/</link>
      <description><![CDATA[你好！ 我在网上看到有人使用 ChatGPT 来帮助他们学习一门新语言。我从来没有想过你可以使用人工智能来学习，但通过与人交谈来学习是一种很好的学习方式。如果你没有人，那么人工智能就在那里。 有人试过使用 ChatGPT、Gemini 或其他人工智能聊天框来学习语言吗？如果试过，哪个平台是最好的？ 谢谢！    提交人    /u/UnintentionalWipe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxvbfe/how_good_is_ai_chatgpt_gemini_etc_when_it_comes/</guid>
      <pubDate>Fri, 10 Jan 2025 03:29:34 GMT</pubDate>
    </item>
    <item>
      <title>调整和优化人工智能的主要原则。重点</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxuuo6/to_align_and_optimize_ai_primary_tenet_fancy_for/</link>
      <description><![CDATA[“我一直相信让事情变得简单——从第一天起，这就是我的生活窍门。每当我面对一个感觉庞大、令人生畏或太多的话题时，我都会采取一个常用的办法：将其分解为一页纸。过去，国会图书馆有一种叫做 Tracer Bullet 的东西。你给他们发送一个主题，他们会发回这份完美的一页纸摘要——没有废话，没有噪音，只有纯粹的知识。每次都是杰作。这就是我带来的能量：现代世界的 Tracer Bullet。 不是大量‘你知道这个吗？’或关于谁是对的琐碎争论。那是儿语。我说的是干净、专注、可分享的知识，我们都可以用来学习、成长和建设。请首先在 Substack 上关注我以获取创意。 ✨ 清晰。 🎯 敏锐。 📚 有用。 在哪里可以找到我 • Substack：https://stonehill.substack.com – 关于人工智能和创造力的长篇论文和反思。 • YouTube：https://youtube.com/stonehills57 – 关于人工智能、网络安全和零信任的视频。 • Threads：https://www.threads.net/@stonehilllsl – 快速思考和创意片段。 • Instagram：https://instagram.com/stonehills57 – 关于人工智能、治理和领导力的专业见解。 • Reddit：https://www.reddit.com/user/stonehills57 – 关于人工智能、国际象棋和诗歌的社区讨论。 • Pinterest：https://www.pinterest.com/greggdotoli – 由我策划的想法和灵感。 这就是我追逐的美丽——我不会停下来，直到它成为现实。    提交人    /u/Stonehills57   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxuuo6/to_align_and_optimize_ai_primary_tenet_fancy_for/</guid>
      <pubDate>Fri, 10 Jan 2025 03:04:58 GMT</pubDate>
    </item>
    <item>
      <title>O系列不同</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxudt3/o_series_is_different/</link>
      <description><![CDATA[当问题稍有变化或以不同的方式提问时，人工智能无法回答问题或至少出现偏差，这是几天前的新闻 我试图用 o1 mini 编写贪吃蛇游戏，这很常见，但扭曲的是蛇的长度应该根据斐波那契数列增加，比如当蛇吃了东西时，它的长度应该是 5 之后的 8，等等 o1 mini 成功了，它可以处理经过任何修改的相同问题，这表明这些系统确实理解并能掌握概念，即使人工智能如此智能，它也是巨大的    提交人    /u/TheLogiqueViper   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxudt3/o_series_is_different/</guid>
      <pubDate>Fri, 10 Jan 2025 02:40:31 GMT</pubDate>
    </item>
    <item>
      <title>英特尔在 CES2025 上发布汽车用英特尔 ARC B 系列</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxts77/intel_announces_on_ces2025_intel_arc_b_series_for/</link>
      <description><![CDATA[https://x.com/intel/status/1877503116012048551 根据英特尔的这篇 X 帖子。 英特尔副总裁在 CES2025 期间宣布推出用于汽车的英特尔 ARC B 系列，它可以运行大型语言模型而无需访问云端。 您对此有何看法？    提交人    /u/abentofreire   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxts77/intel_announces_on_ces2025_intel_arc_b_series_for/</guid>
      <pubDate>Fri, 10 Jan 2025 02:09:34 GMT</pubDate>
    </item>
    <item>
      <title>对于那些在人工智能兴起之前就读的学生来说，人工智能实际上如何帮助你？你能注意到差异吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxranb/for_those_currently_in_school_who_were_in_school/</link>
      <description><![CDATA[我去年写过这篇文章：抓住时机：为什么现在是重返校园的最佳时机。所以我想我应该弄清楚这到底是怎么回事，看看它是否真的有帮助。 https://medium.com/@olimiemma/seize-the-moment-why-now-is-the-perfect-time-to-go-back-to-school-041275bfebab    提交人    /u/Pay-Me-No-Mind   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxranb/for_those_currently_in_school_who_were_in_school/</guid>
      <pubDate>Fri, 10 Jan 2025 00:05:14 GMT</pubDate>
    </item>
    <item>
      <title>人工智能可以自我训练吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxqsvd/can_ai_train_itself/</link>
      <description><![CDATA[当 AI 聊天机器人生成输出时，AI 是否会根据其创建的输出数据进行自我训练？如果没有，为什么它不能这样做？这似乎是它获取训练数据的一种非常简单的方法。另一方面，它确实似乎是循环的。    提交人    /u/DontTread76   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxqsvd/can_ai_train_itself/</guid>
      <pubDate>Thu, 09 Jan 2025 23:42:03 GMT</pubDate>
    </item>
    <item>
      <title>虚拟细胞是科学的“圣杯”。它正在越来越接近。</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxn5tn/a_virtual_cell_is_a_holy_grail_of_science_its/</link>
      <description><![CDATA[Matteo Wong：“加快细胞研究可以为人类带来巨大的成果——新药和疫苗、癌症治疗，甚至只是对塑造我们生活的基本过程的更深入了解。而且这已经开始发生了。科学家们现在正在设计计算机程序，这些程序可能会解锁模拟人类细胞的能力，使研究人员能够预测药物、突变、病毒或身体中任何其他变化的影响，从而使物理实验更有针对性，更有可能成功。卡内基梅隆大学计算机科学家、阿拉伯联合酋长国穆罕默德·本·扎耶德人工智能大学校长 Eric Xing 告诉我，受 ChatGPT 等大型语言模型的启发，人们希望生成式人工智能能够“解码生物语言，然后说出生物语言”。 https://theatln.tc/NUbo5zTi “就像聊天机器人可以从大量书面语言中辨别风格甚至含义，然后用它来构建类似人类的散文一样，人工智能理论上也可以接受大量生物数据的训练，以提取有关细胞甚至整个生物体的关键信息。这将使研究人员能够创建体内许多细胞的虚拟模型，并对其采取行动。斯坦福大学细胞生物学家 Emma Lundberg 告诉我：“这是生物学的圣杯。” “人们多年来一直梦想着它。” “这些夸张的说法——关于生成式人工智能这种模糊且有争议的技术——听起来可能与技术高管的自私预言非常相似：OpenAI 的 Sam Altman、Google DeepMind 的 Demis Hassabis 和 Anthropic 的 Dario Amodei 都宣称他们的人工智能产品将很快彻底改变医学。 “然而，如果生成式人工智能确实实现了这些愿景，那么结果可能看起来就像 Xing、Lundberg 和其他人一直致力于实现的虚拟细胞……即使在早期——科学家告诉我，这种方法如果被证明可行，可能需要 10 年或 100 年才能完全实现——这表明该技术的最终好处可能不是来自聊天机器人，而是来自更雄心勃勃的东西。” 在此处阅读更多信息：https://theatln.tc/NUbo5zTi    由    /u/theatlantic  提交  [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxn5tn/a_virtual_cell_is_a_holy_grail_of_science_its/</guid>
      <pubDate>Thu, 09 Jan 2025 21:01:42 GMT</pubDate>
    </item>
    <item>
      <title>利用可解释的人工智能进行 LLM 文本归因分析，区分人工撰写的文本和多个 LLM-G 文本</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmzp3/leveraging_explainable_ai_for_llm_text/</link>
      <description><![CDATA[我每天都会查找和总结有趣的 AI 研究论文，这样您就不必费力地浏览所有论文。今天的论文题为“利用可解释的 AI 进行 LLM 文本归因：区分人工编写的文本和多个 LLM 生成的文本”，作者是 Ayat Najjar、Huthaifa I. Ashqar、Omar Darwish 和 Eman Hammad。 本文解决了文本来源识别方面的重大挑战，区分了人工编写的文本和由各种大型语言模型 (LLM) 生成的文章。它阐明了随着人工智能生成的文本的兴起，辨别和归因内容的迫切需要，这对学术诚信和内容原创性具有影响。 主要亮点包括：  双相分类：该方法涉及二元分类以区分人类编写的文本和人工智能生成的文本，然后进行多类分类以区分由五个不同的 LLM 生成的文本：ChatGPT、LLaMA、Google Bard、Claude 和 Perplexity。 准确性和性能：所提出的模型实现了极高的准确率，超越了 GPTZero 等现有模型。论文报告的准确率为 98.5%，而 GPTZero 的准确率为 78.3%，表明在识别完整数据集方面有了显着的改善。 可解释的 AI 集成：使用可解释的 AI (XAI) 技术，研究人员增强了模型透明度，有助于理解决定文本归因的重要特征。该方法有助于创建详细的作者资料，这对于强大的抄袭检测至关重要。 数据集管理：研究中的一个关键步骤是开发一个包含人工编写和 LLM 生成的文本的综合数据集，这有助于测试和改进模型。 抄袭检测：该研究通过强调特定 LLM 工具独有的风格和结构元素，提供了更准确的抄袭检测途径，增强了内容原创性的验证。  这项研究为日益依赖人工智能的世界中内容归属日益严峻的挑战提出了有效的解决方案，为更准确的文本来源验证铺平了道路。 您可以在此处查看完整细分：这里您可以在此处获取完整的原始研究论文：原始论文    提交人    /u/steves1189   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmzp3/leveraging_explainable_ai_for_llm_text/</guid>
      <pubDate>Thu, 09 Jan 2025 20:54:27 GMT</pubDate>
    </item>
    <item>
      <title>人工智能辅助路线规划调查</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmni5/survey_on_ai_assisted_routing/</link>
      <description><![CDATA[大家好， 我想请你们帮帮我。我目前正在学习和撰写一篇关于人工智能辅助路线的论文。为了完成这篇论文，我需要进行一项调查。这项调查非常简单、匿名，最多需要 15 分钟才能填写完毕。如果你们能帮助我，我会非常高兴。这是调查的链接 https://wiwigoettingen.eu.qualtrics.com/jfe/form/SV_8i7Lokn6cV5ToUe    提交人    /u/Fair_Dirt_7169   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmni5/survey_on_ai_assisted_routing/</guid>
      <pubDate>Thu, 09 Jan 2025 20:40:03 GMT</pubDate>
    </item>
    <item>
      <title>还有其他人在研究这个想法吗？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmgoe/is_anyone_else_working_on_this_idea/</link>
      <description><![CDATA[我曾有这个想法，使用逆向强化学习来为法学硕士 (LLM) 检测用户的目标，然后帮助他们实现所检测到的目标。这个想法似乎太简单、太重要了，其他人不应该不研究它。我在 Google Scholar 中查找，我能找到的最接近的东西是协作逆向强化学习。还有其他人在研究这个吗？ 这个想法对我来说非常重要，我打算在写完这篇文章后练习为我的爷爷写一份推销材料。我不认为我具备研究技能来迭代这个想法的细节，所以我能做的最好的事情就是让其他人研究它。希望你们开始研究它，或者也许我会发现已经有一群人在研究它了。我只是认为这是让人工智能帮助人类的最重要和最直接的一步，因为它的奖励功能实际上是为他人服务。 我认为已经有足够的研究来让这个想法发挥作用，但我希望看到开发的一个想法是如何使用视频源之类的东西对多个代理进行逆向强化学习。想到这些想法真的很重要，而我却认为我有足够的脑力来拼凑研究论文，而不是提出原创研究，这让我很痛苦。 从字面上看，它的奖励功能就是为他人服务。为什么这么简单的想法没有引起任何关注？！ 编辑：这是我写的简短销售宣传： 想象一下，一个人工智能会不遗余力地问你喜欢什么，而不是等你告诉它。想象一下，一个人工智能会用最甜蜜、最有爱心和最友好的方式与你交谈，而不是一些公司商务用语。想象一下，一个人工智能会从你对它的回应方式中检测出你最微妙的偏好。想象一下，即使你目光短浅，无法抵挡诱惑，人工智能也会将你的最大利益放在心上。 有一种更简单的方法来实现它，即让所有用户更加相爱。我想还有一种更难实现的方法，即让用户不加区别地更加爱护每个人。 这不仅仅是幻想。它基于非常具体的逆向强化学习理念。    提交人    /u/NeuroPyrox   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxmgoe/is_anyone_else_working_on_this_idea/</guid>
      <pubDate>Thu, 09 Jan 2025 20:31:59 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek v3 的思路链为何如此有效？看示例</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxltnt/how_does_deepseek_v3s_chain_of_thought_work_so/</link>
      <description><![CDATA[我尝试了 DeepSeek v3 的思维链推理，基于树的思维链具有回溯其步骤的能力，让我措手不及。 有人有过类似的经历吗？或者任何其他模型？老实说，我没有使用过 O1 Pro，但最初的 o1-preview 和 Gemini 2 的 COT 并不那么复杂。 有什么线索可以说明他们是如何做到的？就 COT 而言，当前的 SOTA 是什么？ 在评论中添加实际的想法。它很庞大，因为它思考了 88 秒并给出了深思熟虑的答案。 COT 要点链接：https://gist.github.com/rajatady/11dbf4c65046c4bb4688c1c4b07122b0    提交人    /u/Consistent_Yak6765   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxltnt/how_does_deepseek_v3s_chain_of_thought_work_so/</guid>
      <pubDate>Thu, 09 Jan 2025 20:04:45 GMT</pubDate>
    </item>
    <item>
      <title>个人人工智能克隆：仅仅经过 2 小时的对话，谷歌就能创造出你个性的数字版本——我不知道对此该作何感想......</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxkp9a/personal_ai_clones_after_just_2_hours_of/</link>
      <description><![CDATA[刚刚阅读了谷歌/斯坦福关于人工智能个性复制的最新研究，它既令人印象深刻又令人担忧。他们开发了一个系统，可以通过一次两小时的采访以 85%（无论这到底意味着什么）的准确率模拟个人决策模式。 技术方法是可靠的：1,052 名参与者，结构化访谈，根据 GSS 和 BFI 框架进行验证。每次采访产生约 6.5k 个单词，足以训练个性化人工智能模型。有趣的是，经济决策游戏中的准确率下降到 66%，这表明当前的建模能力存在局限性。 影响重大：对研究和政策测试很有价值，但对安全性令人担忧。当前的深度伪造骗局已经存在问题——加上个性复制，社会工程学将变得更加危险。 很想听听科技界其他人的想法。我们应该推动哪些保障措施？我们如何在研究实用性和隐私问题之间划清界限？ https://gizmodo.com/google-researchers-can-create-an-ai-that-thinks-a-lot-like-you-after-just-a-two-hour-interview-2000547704    提交人    /u/iamkrulliam   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxkp9a/personal_ai_clones_after_just_2_hours_of/</guid>
      <pubDate>Thu, 09 Jan 2025 19:17:52 GMT</pubDate>
    </item>
    <item>
      <title>人工智能如何避免从错误信息中“学习”？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hxk3sd/how_does_ai_avoid_learning_from_misinformation/</link>
      <description><![CDATA[人工智能基本上是在“互联网”这个数据集上进行“训练”的。互联网包含错误信息，也包含事实。那么“训练过程”如何避免受到错误信息的影响？ 进一步思考，互联网充满了虚构、喜剧、讽刺等。人工智能的学习过程如何避免受到这些内容的影响？    提交人    /u/Steerpike58   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hxk3sd/how_does_ai_avoid_learning_from_misinformation/</guid>
      <pubDate>Thu, 09 Jan 2025 18:52:57 GMT</pubDate>
    </item>
    <item>
      <title>如果我们希望人工智能取得成功，我们就需要人工智能的这一传奇失败并结束</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hx9sk4/if_we_want_ai_to_succeed_we_need_this_saga_of_ai/</link>
      <description><![CDATA[]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hx9sk4/if_we_want_ai_to_succeed_we_need_this_saga_of_ai/</guid>
      <pubDate>Thu, 09 Jan 2025 10:18:50 GMT</pubDate>
    </item>
    <item>
      <title>什么是情报？</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hx8vd2/what_is_intelligence/</link>
      <description><![CDATA[牛津高阶英汉双解词典将智能定义为学习、理解和逻辑思考事物的能力。 但从根本上讲，这到底意味着什么？ 业界似乎高度专注于迭代预先训练的 LLM，这些 LLM 可在数据集中找到模式，并根据训练生成输出。但这真的是智能吗？ 这些模型本身并不理解任何东西。它们接受输入、识别模式并产生与训练期间看到的场景最相似的输出。这与我对智能的理解不一致 - 感觉更像是复杂的模式匹配。 我探索了许多兔子洞，从使用传统 AI 构建交易机器人到映射数据集中的预定义关系模式以获得真正的商业智能（业内人士称之为 BI）。而我不断回到同一个基本事实： 智能不是关于反刍 - 而是关于关系。它是关于理解数据之间的固有关系，并观察这些关系在从不同角度或上下文来看时如何演变。 现有的强力张量训练无法提供透明度或对决策的真正洞察。它只是提供与其训练/测试参数“最接近匹配”的输出。没有真正的理解感，没有深度。 那么，我问你：你如何定义智能？你认为我们目前的方法缺少什么？ xoxo    提交人    /u/Internal_Vibe   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hx8vd2/what_is_intelligence/</guid>
      <pubDate>Thu, 09 Jan 2025 09:08:03 GMT</pubDate>
    </item>
    <item>
      <title>每月“是否有一个工具可以……”帖子</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</link>
      <description><![CDATA[如果您有一个想要使用 AI 的用例，但不知道使用哪种工具，您可以在这里请求社区提供帮助，在此帖子之外，这些问题将被删除。 对于所有回答者：禁止自我宣传、禁止参考或跟踪链接。    提交人    /u/AutoModerator   [link] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4p1x/monthly_is_there_a_tool_for_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:09:07 GMT</pubDate>
    </item>
    <item>
      <title>每月自我推销贴</title>
      <link>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</link>
      <description><![CDATA[如果您有产品要推广，可以在这里进行推广，本帖之外的内容将被删除。  禁止引用链接或带有 utms 的链接，请遵守我们的推广规则。    提交人    /u/AutoModerator   [链接] [评论]]]></description>
      <guid>https://www.reddit.com/r/ArtificialInteligence/comments/1hr4l16/monthly_self_promotion_post/</guid>
      <pubDate>Wed, 01 Jan 2025 15:03:08 GMT</pubDate>
    </item>
    </channel>
</rss>